{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "association_test.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhanschristiansen/association_algo_performance/blob/master/src/association_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6d1IqVaDZZa",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## The Association Process Testing\n",
        "\n",
        "This file documents the process of performing association between lidar reading and detected bounding boxes of objects in the feild of view of both a video camera and a LeddarTech M16 Lidar Detector.\n",
        "\n",
        "#### Background\n",
        "\n",
        "__LIDAR Detector__\n",
        "\n",
        "The LeddarTech M16 provides a non-scanning lidar measurement which returns high sampling speed distance measurements from 16 lidar zones that are arrayed from left to right in a 45 degree field of view horizontally and 7.5 degrees vertically. The individual segments cover equal angles of about 2.8 degrees horizontally and 7.5 degrees vertically. Each LeddarTech reading consists of a segment number (0-15) and a distance reading. There may be zero, one or more distance measurements per segment depending on objects that are in the field of view. The range of the M16 is about 140 feet.\n",
        "\n",
        "__Video Object Detector__\n",
        "\n",
        "The setup uses the Tensorflow Deep Learning software package https://www.tensorflow.org/ and the YOLOv3 model https://github.com/maiminh1996/YOLOv3-tensorflow to detect objects in the field of view of the camera.\n",
        "\n",
        "__Association__\n",
        "\n",
        "having both distance and object detection information available is extremely valuable but it is highly important that we know which lidar distance reading is associated with which object returned from the video object detector. This is __The Association Problem__ that is developed and tested in this notebook.\n",
        "\n",
        "\n",
        "#### Description of the Problem\n",
        "\n",
        "The drawing below shows a 3d Projection of the LeddarTech M16 field of view onto the field of view of the video camera.\n",
        "\n",
        "<html><img src=https://github.com/rhanschristiansen/association_algo_performance/blob/master/src/images/Fields_of_View.jpg?raw=1 width=560></html>\n",
        "\n",
        "When the setup is deployed in the field, the information that is retrieved for a single frame looks like the image below. Here you can see the lidar zones of the M16 shown with thin black lines across the lower middle of the image. \n",
        "\n",
        "__Displaying Lidar Readings__\n",
        "\n",
        "If a zone of the lidar detector returns a distance reading the zone is highlighted in yellow and the distance reading (in feet) is displayed above the lidar zone. If more than one value is returned for a given zone, multiple red distance readings are stacked vertically over the lidar zone. \n",
        "\n",
        "__Displaying Video Detections__\n",
        "\n",
        "The object detections that are returned from the TensorFlow Yolo detector are shown as green bounding boxes. The class of the object are also shown in green text in the lower left corner of the bounding box.\n",
        "\n",
        "In the frame below, there were 5 lidar distance readings returned in zones 4, 5, 6, 7 & 8. And there were 3 objects detected. In this scenario, a fairly simple algorithm could be developed to map lidar values to objects.\n",
        "\n",
        "These are the video detection objects:\n",
        "\n",
        "|Object # | Bounding Box (x1, y1, x2, y2) | Object Class | Confidence |\n",
        "| :-----: | :---------------------------: | :----------: | :--------: |\n",
        "|    1    |   (495, 354, 561, 409)        |    Car       |  0.9839655 |\n",
        "|    2    |   (663, 366, 697, 392)        |    Car       |  0.980555  |\n",
        "|    3    |   (598, 368, 667, 420)        |    Car       |  0.9420464 |\n",
        "\n",
        "And these are the lidar detections:\n",
        "\n",
        "|Detection # | Segment |   Distance   |\n",
        "| :--------: | :-----: | :----------: | \n",
        "|    1       |    4    | 105.799030   |\n",
        "|    2       |    5    | 105.018769   |\n",
        "|    3       |    6    | 104.506889   |\n",
        "|    4       |    7    |  88.595796   |\n",
        "|    5       |    8    |  88.714592   |\n",
        "\n",
        "<html><img src=https://github.com/rhanschristiansen/association_algo_performance/blob/master/src/images/lidar_to_image_rendering_14.png?raw=1 width=1280></html>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssk3Gb3WDZZc",
        "colab_type": "text"
      },
      "source": [
        "However, in other situations, the situation is much more complex. Observe the complexity of the situation when more objects and lidar readings are detected. In this frame shown below, there are a total of 8 objects and 23 lidar detections. This presents a significant challenge to any association algorithm.\n",
        "\n",
        "In this frame, these are the video detection objects:\n",
        "\n",
        "|Object # | Bounding Box (x1, y1, x2, y2) | Object Class | Confidence  |\n",
        "| :-----: | :---------------------------: | :----------: | :---------: |\n",
        "|    1    |   ( -7, 317, 427, 621)        |    Car       |  0.9997973  |\n",
        "|    2    |   (786, 354, 1027, 504)       |    Car       |  0.9997645  |\n",
        "|    3    |   (380, 360, 512, 454)        |    Car       |  0.99277544 |\n",
        "|    4    |   (1129, 418, 1270, 713)      |    Car       |  0.9813789  |\n",
        "|    5    |   (589, 371, 669, 420)        |    Car       |  0.97814137 |\n",
        "|    6    |   (741, 363, 825, 440)        |    Car       |  0.9496468  |\n",
        "|    7    |   (707, 372, 738, 407)        |    Car       |  0.8582622  |\n",
        "|    8    |   (517, 355, 578, 410)        |    Car       |  0.8155548  |\n",
        "\n",
        "And these are the lidar detections:\n",
        "\n",
        "|Detection # | Segment |   Distance   |\n",
        "| :--------: | :-----: | :----------: | \n",
        "|    1       |    0    |   20.352862  |\n",
        "|    2       |    3    |   51.171712  |\n",
        "|    3       |    4    |   50.816675  |\n",
        "|    4       |    5    |   50.729818  |\n",
        "|    5       |    5    |   91.829979  |\n",
        "|    6       |    6    |   91.648105  |\n",
        "|    7       |    7    |   85.183094  |\n",
        "|    8       |    7    |  112.802604  |\n",
        "|    9       |    8    |   84.882674  |\n",
        "|   10       |    8    |  111.584855  |\n",
        "|   11       |    9    |   84.740849  |\n",
        "|   12       |    9    |  112.994140  |\n",
        "|   13       |   10    |   59.250310  |\n",
        "|   14       |   10    |   84.906053  |\n",
        "|   15       |   11    |   59.656511  |\n",
        "|   16       |   12    |   34.480209  |\n",
        "|   17       |   13    |   35.184426  |\n",
        "|   18       |   13    |  108.944754  |\n",
        "|   19       |   14    |   35.332408  |\n",
        "|   20       |   14    |  108.647988  |\n",
        "|   21       |   15    |   35.796530  |\n",
        "|   22       |   14    |   37.425736  |\n",
        "|   23       |   14    |  110.845094  |\n",
        "\n",
        "<html><img src=https://github.com/rhanschristiansen/association_algo_performance/blob/master/src/images/lidar_to_image_rendering_19.png?raw=1 width=1280></html>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVbowpnyDZZd",
        "colab_type": "text"
      },
      "source": [
        "### Solving the Association Problem\n",
        "\n",
        "The image below shows a close up of the simplest association problem so that we can outine an algorithm to address the solution.\n",
        "\n",
        "<html><img src=https://github.com/rhanschristiansen/association_algo_performance/blob/master/src/images/closeup_association.png?raw=1 width=560></html>\n",
        "\n",
        "These are the video detection objects (in green):\n",
        "\n",
        "|Object # | Bounding Box (x1, y1, x2, y2) | Object Class | Confidence |\n",
        "| :-----: | :---------------------------: | :----------: | :--------: |\n",
        "|    1    |   (495, 354, 561, 409)        |    Car       |  0.9839655 |\n",
        "|    2    |   (663, 366, 697, 392)        |    Car       |  0.980555  |\n",
        "|    3    |   (598, 368, 667, 420)        |    Car       |  0.9420464 |\n",
        "\n",
        "From left to right the three objects are 1, 3 & 2 \n",
        "\n",
        "And these are the lidar detections (in red):\n",
        "\n",
        "|Detection # | Segment |   Distance   |\n",
        "| :--------: | :-----: | :----------: | \n",
        "|    1       |    4    | 105.799030   |\n",
        "|    2       |    5    | 105.018769   |\n",
        "|    3       |    6    | 104.506889   |\n",
        "|    4       |    7    |  88.595796   |\n",
        "|    5       |    8    |  88.714592   |\n",
        "\n",
        "From left to right the lidar detections are in numerical order 1, 2, 3, 4 & 5 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHDYS3YODZZd",
        "colab_type": "text"
      },
      "source": [
        "From the data above, using our intuition we could make the following proposals for rules:\n",
        "\n",
        ">1) A lidar reading can only be associated with the object if the object bounding box intersects the segment of the lidar region\n",
        "\n",
        "If we represent an associations matrix with objects in rows and lidar detections in columns and with ones in position (i,j) representing an association between object i and lidar detection j. \n",
        "\n",
        "Using rule #1 we would have the following associations matrix:\n",
        "\n",
        "| Obj# \\ Det# |  1  |  2  |  3  |  4  |  5  |\n",
        "| ----------: | :-: | :-: | :-: | :-: | :-: | \n",
        "|      1      |  0  |  1  |  1  |  0  |  0  |\n",
        "|      2      |  0  |  0  |  0  |  0  |  1  |\n",
        "|      3      |  0  |  0  |  0  |  1  |  1  |\n",
        "\n",
        "Unfortunately, objects 1 and 3 both have two different lidar readings associated with them and lidar reading 5 is associated with two different objects.\n",
        "\n",
        "For the second case, shown above, the association matrix would be significantly more complex:\n",
        "\n",
        "| Obj# \\ Det# |  1  |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  | 10  | 11  | 12  | 13  | 14  | 15  | 16  | 17  | 18  | 19  | 20  | 21  | 22  | 23  |\n",
        "| ----------: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | \n",
        "|      1      |  1  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |\n",
        "|      2      |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  1  |  1  |  1  |  1  |  1  |  1  |  1  |  1  |  1  |  1  |  1  |\n",
        "|      3      |  0  |  1  |  1  |  1  |  1  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |\n",
        "|      4      |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |\n",
        "|      5      |  0  |  0  |  0  |  0  |  0  |  0  |  1  |  1  |  1  |  1  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |\n",
        "|      6      |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  1  |  1  |  1  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |\n",
        "|      7      |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  1  |  1  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |\n",
        "|      8      |  0  |  0  |  0  |  1  |  1  |  1  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |  0  |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8otLGtvDZZe",
        "colab_type": "text"
      },
      "source": [
        "In this case we have most objects with more than one lidar reading associated with them and several lidar readings that are associated with more than one object.\n",
        "\n",
        "One approach that could be attempted is to develop a rules based approach for choosing the best lidar reading for each individual object. Once possible rule might be:\n",
        "\n",
        ">2) When more than one lidar reading is associated with an object based on rule #1 above, choose the lidar reading with the closest distance.\n",
        "\n",
        "Unfortunately, using this rule leads to an conflict with objects 3 and 8 that are both associated with lidar reading #4 using rule 2 which has the lowest distance. By observation, it is clear that lidar reading #4 should be associated with object #8 rather than object #2 because object #8 is the closer object that is closer than object #2.\n",
        "\n",
        "By trying to create a rules based approach to solve the dilemma, we can run into an endless set of rules that are complex and self-contradictory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gZcHtqODZZf",
        "colab_type": "text"
      },
      "source": [
        "### The Hungarian Algorithm\n",
        "\n",
        "One of the methods to solve this assignment problem is the __Hungarian Algorithm__ http://hungarianalgorithm.com/index.php or one of its variants called the __Munkres Algorithm__ http://csclab.murraystate.edu/~bob.pilgrim/445/munkres.html. The Munk-Res algorithm is similar to the Hungarian algorithm but works with non-square matrices.\n",
        "\n",
        "\n",
        "#### The cost function\n",
        "\n",
        "The input to the Munkres Algorithm is a cost function matrix which defines a __cost__ value for each object/lidar detection assignment pair. The Munkres Algotithm will return an assignment matrix or assignment pairs where the overall sum of the costs for all the assignments is minimized. \n",
        "\n",
        "To make the algorithm work it is necessary to create a cost function that decreases as the quality of the assignment increases.\n",
        "\n",
        "#### The Ideal Bounding Box\n",
        "\n",
        "__Possible Cost Functions__\n",
        "\n",
        "Several possible cost functions can be developed for the input to the Munkres Algorithm\n",
        "\n",
        ">1) The L2 Norm - "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJoMRstiEbWk",
        "colab_type": "text"
      },
      "source": [
        "# Colab Environment Setup\n",
        "Download the supporting source files and data to the Colab environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsiI3iZUEyb9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4f731a1d-a253-4f6b-8e0d-fcdc444be6a6"
      },
      "source": [
        "def clone_source_code():\n",
        "  \"\"\"\n",
        "  Clone the github repo and move to this working directory\n",
        "  \"\"\"\n",
        "  print(\"Downloading source code...\")\n",
        "  !_=$(git clone --quiet https://github.com/rhanschristiansen/association_algo_performance.git)\n",
        "  !mv association_algo_performance/* .\n",
        "  !rm -rf association_algo_performance/\n",
        "\n",
        "def download_extract_data():\n",
        "  \"\"\"\n",
        "  Download data.zip from Google Drive and extract to this working directory\n",
        "  \"\"\"\n",
        "  print(\"Downloading data...\")\n",
        "  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1ornFmw59u_It0Cpi8yDHRdpW4G_6YLj5\" > /dev/null\n",
        "  !curl -s -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1ornFmw59u_It0Cpi8yDHRdpW4G_6YLj5\" -o \"data.zip\"\n",
        "  print(\"Extracting data...\")\n",
        "  !unzip -q data.zip\n",
        "def download_yolov3_weights():\n",
        "  print(\"Downloading CNN weights...\")\n",
        "  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1pdFmnxLEbezktEbA7tfnVoU50wowXI2r\" > /dev/null\n",
        "  !curl -s -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1pdFmnxLEbezktEbA7tfnVoU50wowXI2r\" -o \"src/detection/yolov3/yolov3.weights\"\n",
        "def setup():\n",
        "  import sys\n",
        "  sys.path.append('./') #add the parent directory to the path\n",
        "  !rm -rf *\n",
        "  clone_source_code()\n",
        "  download_extract_data()\n",
        "  download_yolov3_weights()\n",
        "  print(\"Setup Complete.\")\n",
        "\n",
        "setup()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading source code...\n",
            "Downloading data...\n",
            "Extracting data...\n",
            "Setup Complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huNkCbayQ81J",
        "colab_type": "text"
      },
      "source": [
        "## The Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80K-TTPWDZZ3",
        "colab_type": "text"
      },
      "source": [
        "Build a class called Transform() that contains the function to move from the image plane to the XZ plane"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "bDCtVUAdDZZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This contains the class Transform() from transform.py in the utils directory\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import src.util.calibration_kitti as cal\n",
        "\n",
        "class Transform():\n",
        "    def __init__(self):\n",
        "        self.y_horizon = cal.cal['Y_HORIZON']\n",
        "        self.y_resolution = cal.cal['Y_RESOLUTION']\n",
        "        self.x_center = cal.cal['X_CENTER']\n",
        "        self.x_resolution = cal.cal['X_RESOLUTION']\n",
        "        self.vfov = cal.cal['VFOV']\n",
        "        self.hfov = cal.cal['HFOV']\n",
        "        self.ht_camera = cal.cal['HT_CAMERA']\n",
        "        self.width_car = cal.cal['WIDTH_CAR']\n",
        "        self.length_car = cal.cal['LENGTH_CAR']\n",
        "        self.wl_ratio = self.width_car / self.length_car\n",
        "        self.edge_margin = 0\n",
        "\n",
        "        self.seg_to_pixel_top = cal.SEG_TO_PIXEL_TOP\n",
        "        self.seg_to_pixel_center = cal.SEG_TO_PIXEL_CENTER\n",
        "        self.seg_to_pixel_left = cal.SEG_TO_PIXEL_LEFT\n",
        "        self.seg_to_pixel_right = cal.SEG_TO_PIXEL_RIGHT\n",
        "        self.seg_to_pixel_bottom = cal.SEG_TO_PIXEL_BOTTOM\n",
        "        self.alpha, self.zprime = self._y2_to_alpha_and_zprime()\n",
        "\n",
        "\n",
        "    '''\n",
        "    Function name:  _y2_to_Zprime\n",
        "    Inputs:         calibration variables\n",
        "                    y_resolution, y_horizon, vfov, ht_camera\n",
        "    Output:         a dictionary of Z' values for each value of y2 from \n",
        "                    y_horizon-1 to y_resolution\n",
        "    '''\n",
        "    def _y2_to_alpha_and_zprime(self):\n",
        "        zprime = {}\n",
        "        alpha = {}\n",
        "        for y in range(self.y_resolution, self.y_horizon, -1):\n",
        "            val = (y-self.y_horizon) * self.vfov / self.y_resolution\n",
        "            alpha[y] = val\n",
        "            zprime[y] = self.ht_camera / math.tan(val)\n",
        "        return alpha, zprime\n",
        "\n",
        "    '''\n",
        "    Function name:  _point_to_distance\n",
        "    Inputs:         y2 - the y2 pixel value of the bounding box \n",
        "                    xc - the x pixel value of the point of interest\n",
        "                    yc - the y pixel value of the point of interest\n",
        "                    \n",
        "    Output:         distance to the point of interest \n",
        "    \n",
        "    equation:       dist = zprime / cos(beta)\n",
        "                    beta = sqrt((xc-x_center)^2 + (yc-ycenter)^2) / Y2    \n",
        "    '''\n",
        "    def _point_to_distance(self, y2, cent):\n",
        "        if y2 > self.y_horizon and y2 <= self.y_resolution:\n",
        "            dist_pixels = math.sqrt((cent[0] - self.x_center)**2 + (cent[1] - self.y_horizon)**2)\n",
        "            beta = dist_pixels / (y2-self.y_horizon) * self.alpha[y2]\n",
        "            dist = self.zprime[y2] / math.cos(beta)\n",
        "            return dist\n",
        "        else:\n",
        "            return 100000 # if y2 is out of bounds return an abitrarily high number\n",
        "\n",
        "    '''\n",
        "    Function:   _x_to_seg_est\n",
        "    Inputs:     x (in pixels)\n",
        "    Output:     a floating point number whose integer value represents the number of the segment.\n",
        "    '''\n",
        "    def _x_to_seg_est(self,x):\n",
        "        return (x - self.seg_to_pixel_left[0])/((self.seg_to_pixel_right[15]-self.seg_to_pixel_left[0])/16)\n",
        "\n",
        "    '''\n",
        "    Function name:  _find_seg_intersections\n",
        "    Inputs:         bb [x1,y1,x2,y2]\n",
        "    Output:         list of lists intersecting segment numbers\n",
        "    '''\n",
        "    def find_seg_intersections(self,bbs):\n",
        "        segs_list = []\n",
        "        for bb in bbs:\n",
        "            toohigh = bb[3] < self.seg_to_pixel_top\n",
        "            toolow = bb[1] > self.seg_to_pixel_bottom\n",
        "            if not (toohigh or toolow):\n",
        "                seg_left = int(self._x_to_seg_est(bb[0]))\n",
        "                seg_right = self._x_to_seg_est(bb[2])\n",
        "                segs = [x for i,x in enumerate(range(0,16)) if x >= seg_left and x < seg_right]\n",
        "                segs_list.append(segs)\n",
        "            else:\n",
        "                segs_list.append([])\n",
        "        return segs_list\n",
        "\n",
        "    '''\n",
        "    Function name:  _find_seg_centroids\n",
        "    Inputs:         bb, seg\n",
        "    Outputs:        a list of (xc, yc) tuples corresponding to the seg list\n",
        "    Method:         the function finds the intersecting area of the bounding box and the \n",
        "                    bounding box and returns the centroid of the intersecting area\n",
        "    '''\n",
        "    def _find_seg_centroids(self,bb,segs):\n",
        "        cents = []\n",
        "        for seg in segs:\n",
        "            xvals = [bb[0],bb[2],self.seg_to_pixel_left[int(seg)],self.seg_to_pixel_right[int(seg)]]\n",
        "            xvals.sort()\n",
        "            yvals = [bb[1],bb[3],self.seg_to_pixel_top,self.seg_to_pixel_bottom]\n",
        "            yvals.sort()\n",
        "            cents.append((int((xvals[1] + xvals[2])/2),int((yvals[1] + yvals[2])/2)))\n",
        "        return cents\n",
        "\n",
        "    '''\n",
        "    Function name:  bb_to_dist_seg\n",
        "    Inputs:         a list containing [x1, y1, x2, y2]\n",
        "                    which is the bounding box coordinates in the pixel space\n",
        "    Output:         a list containing a list of intersecting segments numbers 0-15 and a \n",
        "                    list of the corresponding distance estimates\n",
        "    '''\n",
        "\n",
        "    def bb_to_dist_seg_list(self,bb):\n",
        "        dists_list = []\n",
        "        segs_list = self.find_seg_intersections(bb)\n",
        "        for i, segs in enumerate(segs_list):\n",
        "            cents = self._find_seg_centroids(bb[i],segs_list[i])\n",
        "            dists = []\n",
        "            for cent in cents:\n",
        "                dist = self._point_to_distance(bb[i][3],cent)\n",
        "                dists.append(dist)\n",
        "            dists_list.append(dists)\n",
        "        return dists_list, segs_list\n",
        "\n",
        "    '''\n",
        "    Function name:  bb_dist_to_XZ\n",
        "    Inputs:         a list of lists containing [x1, y1, x2, y2, dist]\n",
        "                    which is the bounding box coordinates in the pixel space and\n",
        "                    the dist in ft in the XZ space\n",
        "    Output:         a list of lists of [X, Z] tuples for each list in the input\n",
        "    '''\n",
        "\n",
        "    def bb_dist_to_XZ(self,bb_dist_lists):\n",
        "        XZ_lists = []\n",
        "        for i, bb_dist_list in enumerate(bb_dist_lists):\n",
        "\n",
        "            # x_c and y_c are the coordinates of the centroid of the bounding box in the pixel plane xy\n",
        "            x_c = (bb_dist_list[0] + bb_dist_list[2]) / 2\n",
        "            y_c = (bb_dist_list[1] + bb_dist_list[3]) / 2\n",
        "\n",
        "            # hypotenus_xy is the distance in pixels from the center of optical flow\n",
        "            # and the centroid of the bounding box in the pixel coordinate system\n",
        "            hypotenus_xy = math.sqrt((x_c - self.x_center)**2 + (y_c - self.y_horizon)**2)\n",
        "\n",
        "            # beta is the angle between the line extending from the camera to the center of optical flow\n",
        "            # and the line extending from the camera to the center of the object in the world coordinate system\n",
        "            beta = hypotenus_xy * self.hfov / self.x_resolution\n",
        "\n",
        "            # Z is the Z coordinate of the object in the world coordinate system\n",
        "            Z = bb_dist_list[4] * math.cos(beta)\n",
        "\n",
        "            # hypotenus_XY is the distance in feet between the point (0, 0, Z) and (Xc, Yc, Z)\n",
        "            # in the world coordinate system on the plane parallel to XY\n",
        "            # that intersects the back of the detected object\n",
        "            hypotenus_XY = bb_dist_list[4] * math.sin(beta)\n",
        "\n",
        "            # X is the X coordinate of the object in the world coordinate system\n",
        "            X = x_c / hypotenus_xy * hypotenus_XY\n",
        "            XZ_lists.append([X,Z])\n",
        "\n",
        "        return XZ_lists\n",
        "\n",
        "    # this function calculates the ideal bounding box for the lidar detection\n",
        "    def lidar_dist_seg_to_bb(self, dist, seg):\n",
        "\n",
        "        y2 = int(cal.cal['FOCAL_LENGTH'] * cal.cal['HT_CAMERA'] / dist + cal.cal['Y_HORIZON'])\n",
        "\n",
        "        x_width =  cal.cal['WIDTH_CAR'] / dist * cal.cal['FOCAL_LENGTH']\n",
        "\n",
        "        beta = math.radians(cal.SEG_TO_ANGLE[seg])\n",
        "        x_mid = cal.cal['X_CENTER'] + beta / cal.cal['HFOV'] * cal.cal['X_RESOLUTION']\n",
        "\n",
        "        x1 = int(x_mid - x_width / 2)\n",
        "        x2 = int(x_mid + x_width / 2)\n",
        "        y1 = int(y2 - x_width)\n",
        "\n",
        "        return [x1, y1, x2, y2]\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNBW3lOwDZZ9",
        "colab_type": "text"
      },
      "source": [
        "Next, we bring in a class to contain instances of the Lidar Detections "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0,
          4
        ],
        "id": "UjdlptuIDZZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# This contains the class LIDAR_detection() from lidar_detection.py in robert@verix-6440:~$ cd ~/PycharmProjects/\n",
        "from src.util.transform import Transform\n",
        "\n",
        "class LIDAR_detection():\n",
        "    def __init__(self, frame, seg, dist, ampl):\n",
        "        tr = Transform()\n",
        "        self.frame = frame\n",
        "        self.dist = dist\n",
        "        self.seg = seg\n",
        "        self.bb = tr.lidar_dist_seg_to_bb(dist, seg)\n",
        "        self.ampl = ampl\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7GF36ttDZaD",
        "colab_type": "text"
      },
      "source": [
        "The next class is the car detector that uses the yolo v3 Tensorflow based Convolutional Nueral Network to detect cars, trucks and vans."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "VR5aST28DZaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This contains the class CarDetectorTFV2() from car_detector_tf_v2.py in the detection directory\n",
        "\n",
        "\"\"\"\n",
        "Car detector using tensorflow models\n",
        "TODO: move into a class\n",
        "\"\"\"\n",
        "import os\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from src.detection.yolov3 import yolov3\n",
        "\n",
        "class CarDetectorTFV2(object):\n",
        "    def __init__(self):\n",
        "        tf.reset_default_graph()\n",
        "        self.session = tf.Session()\n",
        "        self.batch_size = 1\n",
        "        self.max_output_size = 10\n",
        "        self.iou_threshold = 0.5\n",
        "        self.confidence_threshold = 0.5\n",
        "        self.model = yolov3.Yolo_v3(max_output_size=self.max_output_size,\n",
        "                                    iou_threshold=self.iou_threshold,\n",
        "                                    confidence_threshold=self.confidence_threshold)\n",
        "        self.class_names = self.model.class_names\n",
        "        self.model_size = self.model.model_size\n",
        "        self.inputs = tf.placeholder(tf.float32, [self.batch_size, self.model_size[0], self.model_size[1], 3])\n",
        "        self.run_inference = self.model(self.inputs, training=False)\n",
        "        self.model_vars = tf.global_variables(scope='yolo_v3_model')\n",
        "        self.assign_ops = yolov3.load_weights(self.model_vars, self.model.weights_path)\n",
        "        self.session.run(self.assign_ops)\n",
        "\n",
        "    def detect(self, img, return_class_scores=False):\n",
        "        \"\"\"\n",
        "        Given input image, return detections\n",
        "        \"\"\"\n",
        "        detection_boxes, detection_classes, detection_scores = [], [], []\n",
        "        img_net = cv2.resize(img, (self.model_size[0], self.model_size[1]))\n",
        "        batch = np.array([img_net])\n",
        "        detection_result = self.session.run(self.run_inference, feed_dict={self.inputs: batch})\n",
        "        det = detection_result[0]\n",
        "        resize_factor = (img.shape[1] / self.model_size[0], img.shape[0] / self.model_size[1])\n",
        "        for cls in range(len(self.class_names)):\n",
        "            boxes = det[cls]\n",
        "            if np.size(boxes) != 0:\n",
        "                for box in boxes:\n",
        "                    xy, confidence = box[:4], box[4]\n",
        "                    xy = [int(xy[i] * resize_factor[i % 2]) for i in range(4)]\n",
        "                    x1, y1, x2, y2 = xy[0], xy[1], xy[2], xy[3]\n",
        "                    bbox = [x1, y1, x2, y2]\n",
        "                    detection_boxes.append(bbox)\n",
        "                    detection_classes.append(self.class_names[cls])\n",
        "                    detection_scores.append(confidence)\n",
        "        if return_class_scores:\n",
        "            return detection_boxes, detection_classes, detection_scores\n",
        "        else:\n",
        "            return detection_boxes\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z1qTkk5DZaK",
        "colab_type": "text"
      },
      "source": [
        "The next class is the Costs() class that defines the various cost functions that are used in the association process and finally passed to the Munkres algorithm for assignment of Lidar Detections to Video Detections  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0,
          13
        ],
        "id": "j0zsNFShDZaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This contains the class Costs() from costs.py in the associations directory\n",
        "\n",
        "import math\n",
        "import src.util.calibration_kitti as cal\n",
        "import numpy as np\n",
        "from src.util.transform import Transform\n",
        "\n",
        "# the class Costs contains methods that individually calculate the cost_arrays for use by the Munkres algorithm\n",
        "# Each of the methods receives the lidar_detections and video_detections lists as values in the **kwargs dictionary\n",
        "# Each of the methods returns a cost array with values designed to be between 0 and 1\n",
        "# the cost array should have the number of rows equal to the number of video detection objects in the video_detections list\n",
        "# and the number of columns equal to the number of lidar detection objects in the lidar_detections list.\n",
        "\n",
        "class Costs():\n",
        "    def __init__(self):\n",
        "        self.tr = Transform()\n",
        "\n",
        "    # this method calculates the euclidian distance between the centroid of the video_detection bounding box and the\n",
        "    # centroid of the lidar detection ideal bounding box. The distance in pixels is divided by the diagonal of the\n",
        "    # video image in pixels to give a value between 0 and 1\n",
        "    def dist_between_centroids(self, **kwargs):\n",
        "#        max_dist = math.sqrt(cal.cal['X_RESOLUTION']**2 + cal.cal['Y_RESOLUTION']**2) # max dist between centroids used\n",
        "        LIDAR_X_RES = cal.SEG_TO_PIXEL_RIGHT[8] - cal.SEG_TO_PIXEL_LEFT[0]\n",
        "        LIDAR_Y_RES = cal.SEG_TO_PIXEL_BOTTOM - cal.SEG_TO_PIXEL_TOP\n",
        "\n",
        "        max_dist = math.sqrt(LIDAR_X_RES**2 + LIDAR_Y_RES**2) # max dist between centroids used to normalize between 0 and 1\n",
        "        video_detections = kwargs['video_detections']\n",
        "        lidar_detections = kwargs['lidar_detections']\n",
        "        dist_array = np.ones((len(video_detections), len(lidar_detections)), np.float64) * 1\n",
        "\n",
        "        for i, video_detection in enumerate(video_detections):\n",
        "            cx_v = (video_detection.bbox[0] + video_detection.bbox[2]) / 2\n",
        "            cy_v = (video_detection.bbox[1] + video_detection.bbox[3]) / 2\n",
        "            for j, lidar_detection in enumerate(lidar_detections):\n",
        "                cx_l = (lidar_detection.bb[0] + lidar_detection.bb[2]) / 2\n",
        "                cy_l = (lidar_detection.bb[1] + lidar_detection.bb[3]) / 2\n",
        "                dist_array[i,j] = math.sqrt( (cx_v-cx_l)**2 + (cy_v-cy_l)**2 ) / max_dist\n",
        "\n",
        "        return dist_array\n",
        "\n",
        "    # this method calculates the difference in feet between the lidar distance and the\n",
        "    # estimated distance derived from the y2 value of the video bounding box. this value is\n",
        "    # divided by the max_lidar distance of 140 feet to give a value between 0 and 1\n",
        "    # if there is no overlap between the video_detection bounding box and the lidar segment\n",
        "    # the cost is penalized with a value of 1e6\n",
        "    def dist_lidar_to_y2estimate(self, **kwargs):\n",
        "        max_dist = 140/2 # maximum detection distance for lidar - used to normalize the output between 0 and 1\n",
        "        m_to_ft = cal.cal['M_TO_FT']\n",
        "        video_detections = kwargs['video_detections']\n",
        "        lidar_detections = kwargs['lidar_detections']\n",
        "        dist_array = np.ones((len(video_detections), len(lidar_detections)), np.float64) * 1\n",
        "        bbs = []\n",
        "        for i in range(len(video_detections)):\n",
        "            bbs.append(list(video_detections[i].bbox))\n",
        "\n",
        "        dists_list, segs_list = self.tr.bb_to_dist_seg_list(bbs)\n",
        "\n",
        "        for i in range(len(dists_list)):\n",
        "            dist_est_array = np.zeros((len(lidar_detections), 1), np.float64)\n",
        "            for j in range(len(lidar_detections)):\n",
        "                for segs, dists in zip(segs_list,dists_list):\n",
        "                    for k, seg in enumerate(segs):\n",
        "                        if seg == lidar_detections[j].seg: # only use values from bounding boxes that overlap the lidar segment\n",
        "                            dist_est = dists[k]\n",
        "                            # add dist_est to fvec in video_detection for later use\n",
        "                            dist_est_array[j,0] = dist_est\n",
        "                            dist_array[i,j] = abs(dist_est - lidar_detections[j].dist) / max_dist\n",
        "            video_detections[i].dist_est_y2 = dist_est_array\n",
        "\n",
        "        return dist_array\n",
        "\n",
        "    # this is a helper function to calculate the intersection / union ratio of the bounding box rectangles.\n",
        "    # the value 0 means there is no intersection\n",
        "    # the value 1 means they bounding boxes are in exactly the same place 100% overlap\n",
        "    def _iou(self, boxA, boxB):\n",
        "\n",
        "        # determine the (x, y)-coordinates of the intersection rectangle\n",
        "        xA = max(boxA[0], boxB[0])\n",
        "        yA = max(boxA[1], boxB[1])\n",
        "        xB = min(boxA[2], boxB[2])\n",
        "        yB = min(boxA[3], boxB[3])\n",
        "\n",
        "        if xA < xB and yA < yB: # calculate area only for overlapping bounding boxes\n",
        "            # compute the area of intersection rectangle\n",
        "            interArea = (xB - xA) * (yB - yA)\n",
        "        else:\n",
        "            interArea = 0\n",
        "\n",
        "        # compute the area of both the prediction and ground-truth\n",
        "        # rectangles\n",
        "        boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "        boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "\n",
        "        union = float(boxAArea + boxBArea - interArea)\n",
        "\n",
        "        # compute the intersection over union by taking the intersection\n",
        "        # area and dividing it by the sum of prediction + ground-truth\n",
        "        # areas - the interesection area\n",
        "        if union > 0:\n",
        "            iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "        else:\n",
        "            iou = 0\n",
        "\n",
        "        return iou\n",
        "\n",
        "    # this method calculates the overlap of the video_detection bounding box and the\n",
        "    # lidar detection ideal bounding box\n",
        "    # The returned values in the array are 1 minus the intersection / union ratio\n",
        "    # a 100% overlap would have a cost of 0 and 1% overlap would have a cost of 0.99\n",
        "    # no overlap is penalized with a value of 1e6\n",
        "    def inverse_intersection_over_union(self, **kwargs):\n",
        "\n",
        "        video_detections = kwargs['video_detections']\n",
        "        lidar_detections = kwargs['lidar_detections']\n",
        "\n",
        "        cost_array = np.ones((len(video_detections), len(lidar_detections)), np.float64) * 1\n",
        "\n",
        "        for i in range(len(video_detections)):\n",
        "            for j in range(len(lidar_detections)):\n",
        "                cost = 1 - self._iou(video_detections[i].bbox, lidar_detections[j].bb) # one minus the iou ratio\n",
        "                if cost < 1: # only use values that are less that 1 (have some overlap between bounding boxes)\n",
        "                    cost_array[i,j] = cost\n",
        "\n",
        "        return cost_array\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux0UGtJJDZaQ",
        "colab_type": "text"
      },
      "source": [
        "Here the Munkres class is defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "sT2SL28JDZaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This contains the class Munkres() from munkres.py in the associations directory\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: iso-8859-1 -*-\n",
        "\n",
        "# Documentation is intended to be processed by Epydoc.\n",
        "\n",
        "\"\"\"\n",
        "Introduction\n",
        "============\n",
        "\n",
        "The Munkres module provides an implementation of the Munkres algorithm\n",
        "(also called the Hungarian algorithm or the Kuhn-Munkres algorithm),\n",
        "useful for solving the Assignment Problem.\n",
        "\n",
        "Assignment Problem\n",
        "==================\n",
        "\n",
        "Let *C* be an *n*\\ x\\ *n* matrix representing the costs of each of *n* workers\n",
        "to perform any of *n* jobs. The assignment problem is to assign jobs to\n",
        "workers in a way that minimizes the total cost. Since each worker can perform\n",
        "only one job and each job can be assigned to only one worker the assignments\n",
        "represent an independent set of the matrix *C*.\n",
        "\n",
        "One way to generate the optimal set is to create all permutations of\n",
        "the indexes necessary to traverse the matrix so that no row and column\n",
        "are used more than once. For instance, given this matrix (expressed in\n",
        "Python)::\n",
        "\n",
        "    matrix = [[5, 9, 1],\n",
        "              [10, 3, 2],\n",
        "              [8, 7, 4]]\n",
        "\n",
        "You could use this code to generate the traversal indexes::\n",
        "\n",
        "    def permute(a, results):\n",
        "        if len(a) == 1:\n",
        "            results.insert(len(results), a)\n",
        "\n",
        "        else:\n",
        "            for i in range(0, len(a)):\n",
        "                element = a[i]\n",
        "                a_copy = [a[j] for j in range(0, len(a)) if j != i]\n",
        "                subresults = []\n",
        "                permute(a_copy, subresults)\n",
        "                for subresult in subresults:\n",
        "                    result = [element] + subresult\n",
        "                    results.insert(len(results), result)\n",
        "\n",
        "    results = []\n",
        "    permute(range(len(matrix)), results) # [0, 1, 2] for a 3x3 matrix\n",
        "\n",
        "After the call to permute(), the results matrix would look like this::\n",
        "\n",
        "    [[0, 1, 2],\n",
        "     [0, 2, 1],\n",
        "     [1, 0, 2],\n",
        "     [1, 2, 0],\n",
        "     [2, 0, 1],\n",
        "     [2, 1, 0]]\n",
        "\n",
        "You could then use that index matrix to loop over the original cost matrix\n",
        "and calculate the smallest cost of the combinations::\n",
        "\n",
        "    n = len(matrix)\n",
        "    minval = sys.maxint\n",
        "    for row in range(n):\n",
        "        cost = 0\n",
        "        for col in range(n):\n",
        "            cost += matrix[row][col]\n",
        "        minval = min(cost, minval)\n",
        "\n",
        "    print minval\n",
        "\n",
        "While this approach works fine for small matrices, it does not scale. It\n",
        "executes in O(*n*!) time: Calculating the permutations for an *n*\\ x\\ *n*\n",
        "matrix requires *n*! operations. For a 12x12 matrix, that's 479,001,600\n",
        "traversals. Even if you could manage to perform each traversal in just one\n",
        "millisecond, it would still take more than 133 hours to perform the entire\n",
        "traversal. A 20x20 matrix would take 2,432,902,008,176,640,000 operations. At\n",
        "an optimistic millisecond per operation, that's more than 77 million years.\n",
        "\n",
        "The Munkres algorithm runs in O(*n*\\ ^3) time, rather than O(*n*!). This\n",
        "package provides an implementation of that algorithm.\n",
        "\n",
        "This version is based on\n",
        "http://www.public.iastate.edu/~ddoty/HungarianAlgorithm.html.\n",
        "\n",
        "This version was written for Python by Brian Clapper from the (Ada) algorithm\n",
        "at the above web site. (The ``Algorithm::Munkres`` Perl version, in CPAN, was\n",
        "clearly adapted from the same web site.)\n",
        "\n",
        "Usage\n",
        "=====\n",
        "\n",
        "Construct a Munkres object::\n",
        "\n",
        "    from munkres import Munkres\n",
        "\n",
        "    m = Munkres()\n",
        "\n",
        "Then use it to compute the lowest cost assignment from a cost matrix. Here's\n",
        "a sample program::\n",
        "\n",
        "    from munkres import Munkres, print_matrix\n",
        "\n",
        "    matrix = [[5, 9, 1],\n",
        "              [10, 3, 2],\n",
        "              [8, 7, 4]]\n",
        "    m = Munkres()\n",
        "    indexes = m.compute(matrix)\n",
        "    print_matrix(matrix, msg='Lowest cost through this matrix:')\n",
        "    total = 0\n",
        "    for row, column in indexes:\n",
        "        value = matrix[row][column]\n",
        "        total += value\n",
        "        print '(%d, %d) -> %d' % (row, column, value)\n",
        "    print 'total cost: %d' % total\n",
        "\n",
        "Running that program produces::\n",
        "\n",
        "    Lowest cost through this matrix:\n",
        "    [5, 9, 1]\n",
        "    [10, 3, 2]\n",
        "    [8, 7, 4]\n",
        "    (0, 0) -> 5\n",
        "    (1, 1) -> 3\n",
        "    (2, 2) -> 4\n",
        "    total cost=12\n",
        "\n",
        "The instantiated Munkres object can be used multiple times on different\n",
        "matrices.\n",
        "\n",
        "Non-square Cost Matrices\n",
        "========================\n",
        "\n",
        "The Munkres algorithm assumes that the cost matrix is square. However, it's\n",
        "possible to use a rectangular matrix if you first pad it with 0 values to make\n",
        "it square. This module automatically pads rectangular cost matrices to make\n",
        "them square.\n",
        "\n",
        "Notes:\n",
        "\n",
        "- The module operates on a *copy* of the caller's matrix, so any padding will\n",
        "  not be seen by the caller.\n",
        "- The cost matrix must be rectangular or square. An irregular matrix will\n",
        "  *not* work.\n",
        "\n",
        "Calculating Profit, Rather than Cost\n",
        "====================================\n",
        "\n",
        "The cost matrix is just that: A cost matrix. The Munkres algorithm finds\n",
        "the combination of elements (one from each row and column) that results in\n",
        "the smallest cost. It's also possible to use the algorithm to maximize\n",
        "profit. To do that, however, you have to convert your profit matrix to a\n",
        "cost matrix. The simplest way to do that is to subtract all elements from a\n",
        "large value. For example::\n",
        "\n",
        "    from munkres import Munkres, print_matrix\n",
        "\n",
        "    matrix = [[5, 9, 1],\n",
        "              [10, 3, 2],\n",
        "              [8, 7, 4]]\n",
        "    cost_matrix = []\n",
        "    for row in matrix:\n",
        "        cost_row = []\n",
        "        for col in row:\n",
        "            cost_row += [sys.maxint - col]\n",
        "        cost_matrix += [cost_row]\n",
        "\n",
        "    m = Munkres()\n",
        "    indexes = m.compute(cost_matrix)\n",
        "    print_matrix(matrix, msg='Highest profit through this matrix:')\n",
        "    total = 0\n",
        "    for row, column in indexes:\n",
        "        value = matrix[row][column]\n",
        "        total += value\n",
        "        print '(%d, %d) -> %d' % (row, column, value)\n",
        "\n",
        "    print 'total profit=%d' % total\n",
        "\n",
        "Running that program produces::\n",
        "\n",
        "    Highest profit through this matrix:\n",
        "    [5, 9, 1]\n",
        "    [10, 3, 2]\n",
        "    [8, 7, 4]\n",
        "    (0, 1) -> 9\n",
        "    (1, 0) -> 10\n",
        "    (2, 2) -> 4\n",
        "    total profit=23\n",
        "\n",
        "The ``munkres`` module provides a convenience method for creating a cost\n",
        "matrix from a profit matrix. Since it doesn't know whether the matrix contains\n",
        "floating point numbers, decimals, or integers, you have to provide the\n",
        "conversion function; but the convenience method takes care of the actual\n",
        "creation of the cost matrix::\n",
        "\n",
        "    import munkres\n",
        "\n",
        "    cost_matrix = munkres.make_cost_matrix(matrix,\n",
        "                                           lambda cost: sys.maxint - cost)\n",
        "\n",
        "So, the above profit-calculation program can be recast as::\n",
        "\n",
        "    from munkres import Munkres, print_matrix, make_cost_matrix\n",
        "\n",
        "    matrix = [[5, 9, 1],\n",
        "              [10, 3, 2],\n",
        "              [8, 7, 4]]\n",
        "    cost_matrix = make_cost_matrix(matrix, lambda cost: sys.maxint - cost)\n",
        "    m = Munkres()\n",
        "    indexes = m.compute(cost_matrix)\n",
        "    print_matrix(matrix, msg='Lowest cost through this matrix:')\n",
        "    total = 0\n",
        "    for row, column in indexes:\n",
        "        value = matrix[row][column]\n",
        "        total += value\n",
        "        print '(%d, %d) -> %d' % (row, column, value)\n",
        "    print 'total profit=%d' % total\n",
        "\n",
        "References\n",
        "==========\n",
        "\n",
        "1. http://www.public.iastate.edu/~ddoty/HungarianAlgorithm.html\n",
        "\n",
        "2. Harold W. Kuhn. The Hungarian Method for the assignment problem.\n",
        "   *Naval Research Logistics Quarterly*, 2:83-97, 1955.\n",
        "\n",
        "3. Harold W. Kuhn. Variants of the Hungarian method for assignment\n",
        "   problems. *Naval Research Logistics Quarterly*, 3: 253-258, 1956.\n",
        "\n",
        "4. Munkres, J. Algorithms for the Assignment and Transportation Problems.\n",
        "   *Journal of the Society of Industrial and Applied Mathematics*,\n",
        "   5(1):32-38, March, 1957.\n",
        "\n",
        "5. http://en.wikipedia.org/wiki/Hungarian_algorithm\n",
        "\n",
        "Copyright and License\n",
        "=====================\n",
        "\n",
        "This software is released under a BSD license, adapted from\n",
        "<http://opensource.org/licenses/bsd-license.php>\n",
        "\n",
        "Copyright (c) 2008 Brian M. Clapper\n",
        "All rights reserved.\n",
        "\n",
        "Redistribution and use in source and binary forms, with or without\n",
        "modification, are permitted provided that the following conditions are met:\n",
        "\n",
        "* Redistributions of source code must retain the above copyright notice,\n",
        "  this list of conditions and the following disclaimer.\n",
        "\n",
        "* Redistributions in binary form must reproduce the above copyright notice,\n",
        "  this list of conditions and the following disclaimer in the documentation\n",
        "  and/or other materials provided with the distribution.\n",
        "\n",
        "* Neither the name \"clapper.org\" nor the names of its contributors may be\n",
        "  used to endorse or promote products derived from this software without\n",
        "  specific prior written permission.\n",
        "\n",
        "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
        "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
        "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
        "ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
        "LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
        "CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
        "SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
        "INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
        "CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
        "ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
        "POSSIBILITY OF SUCH DAMAGE.\n",
        "\"\"\"\n",
        "\n",
        "__docformat__ = 'restructuredtext'\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Imports\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "import sys\n",
        "import copy\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Exports\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "__all__     = ['Munkres', 'make_cost_matrix']\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Globals\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "# Info about the module\n",
        "__version__   = \"1.0.5.5\"\n",
        "__author__    = \"Brian Clapper, bmc@clapper.org\"\n",
        "__url__       = \"http://github.com/datapublica/munkres\"\n",
        "__copyright__ = \"(c) 2008 Brian M. Clapper\"\n",
        "__license__   = \"BSD-style license\"\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Classes\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "class Munkres:\n",
        "    \"\"\"\n",
        "    Calculate the Munkres solution to the classical assignment problem.\n",
        "    See the module documentation for usage.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Create a new instance\"\"\"\n",
        "        self.C = None\n",
        "        self.row_covered = []\n",
        "        self.col_covered = []\n",
        "        self.n = 0\n",
        "        self.Z0_r = 0\n",
        "        self.Z0_c = 0\n",
        "        self.marked = None\n",
        "        self.path = None\n",
        "\n",
        "    def make_cost_matrix(profit_matrix, inversion_function):\n",
        "        \"\"\"\n",
        "        **DEPRECATED**\n",
        "\n",
        "        Please use the module function ``make_cost_matrix()``.\n",
        "        \"\"\"\n",
        "        import munkres\n",
        "        return munkres.make_cost_matrix(profit_matrix, inversion_function)\n",
        "\n",
        "    make_cost_matrix = staticmethod(make_cost_matrix)\n",
        "\n",
        "    def pad_matrix(self, matrix, pad_value=0):\n",
        "        \"\"\"\n",
        "        Pad a possibly non-square matrix to make it square.\n",
        "\n",
        "        :Parameters:\n",
        "            matrix : list of lists\n",
        "                matrix to pad\n",
        "\n",
        "            pad_value : int\n",
        "                value to use to pad the matrix\n",
        "\n",
        "        :rtype: list of lists\n",
        "        :return: a new, possibly padded, matrix\n",
        "        \"\"\"\n",
        "        max_columns = 0\n",
        "        total_rows = len(matrix)\n",
        "\n",
        "        for row in matrix:\n",
        "            max_columns = max(max_columns, len(row))\n",
        "\n",
        "        total_rows = max(max_columns, total_rows)\n",
        "\n",
        "        new_matrix = []\n",
        "        for row in matrix:\n",
        "            row_len = len(row)\n",
        "            new_row = row[:]\n",
        "            if total_rows > row_len:\n",
        "                # Row too short. Pad it.\n",
        "                new_row += [pad_value] * (total_rows - row_len)\n",
        "            new_matrix += [new_row]\n",
        "\n",
        "        while len(new_matrix) < total_rows:\n",
        "            new_matrix += [[pad_value] * total_rows]\n",
        "\n",
        "        return new_matrix\n",
        "\n",
        "    def compute(self, cost_matrix):\n",
        "        \"\"\"\n",
        "        Compute the indexes for the lowest-cost pairings between rows and\n",
        "        columns in the database. Returns a list of (row, column) tuples\n",
        "        that can be used to traverse the matrix.\n",
        "\n",
        "        :Parameters:\n",
        "            cost_matrix : list of lists\n",
        "                The cost matrix. If this cost matrix is not square, it\n",
        "                will be padded with zeros, via a call to ``pad_matrix()``.\n",
        "                (This method does *not* modify the caller's matrix. It\n",
        "                operates on a copy of the matrix.)\n",
        "\n",
        "                **WARNING**: This code handles square and rectangular\n",
        "                matrices. It does *not* handle irregular matrices.\n",
        "\n",
        "        :rtype: list\n",
        "        :return: A list of ``(row, column)`` tuples that describe the lowest\n",
        "                 cost path through the matrix\n",
        "\n",
        "        \"\"\"\n",
        "        self.C = self.pad_matrix(cost_matrix)\n",
        "        self.n = len(self.C)\n",
        "        self.original_length = len(cost_matrix)\n",
        "        self.original_width = len(cost_matrix[0])\n",
        "        self.row_covered = [False for i in range(self.n)]\n",
        "        self.col_covered = [False for i in range(self.n)]\n",
        "        self.Z0_r = 0\n",
        "        self.Z0_c = 0\n",
        "        self.path = self.__make_matrix(self.n * 2, 0)\n",
        "        self.marked = self.__make_matrix(self.n, 0)\n",
        "\n",
        "        done = False\n",
        "        step = 1\n",
        "\n",
        "        steps = { 1 : self.__step1,\n",
        "                  2 : self.__step2,\n",
        "                  3 : self.__step3,\n",
        "                  4 : self.__step4,\n",
        "                  5 : self.__step5,\n",
        "                  6 : self.__step6 }\n",
        "\n",
        "        while not done:\n",
        "            try:\n",
        "                func = steps[step]\n",
        "                step = func()\n",
        "            except KeyError:\n",
        "                done = True\n",
        "\n",
        "        # Look for the starred columns\n",
        "        results = []\n",
        "        for i in range(self.original_length):\n",
        "            for j in range(self.original_width):\n",
        "                if self.marked[i][j] == 1:\n",
        "                    results += [(i, j)]\n",
        "\n",
        "        return results\n",
        "\n",
        "    def __copy_matrix(self, matrix):\n",
        "        \"\"\"Return an exact copy of the supplied matrix\"\"\"\n",
        "        return copy.deepcopy(matrix)\n",
        "\n",
        "    def __make_matrix(self, n, val):\n",
        "        \"\"\"Create an *n*x*n* matrix, populating it with the specific value.\"\"\"\n",
        "        matrix = []\n",
        "        for i in range(n):\n",
        "            matrix += [[val for j in range(n)]]\n",
        "        return matrix\n",
        "\n",
        "    def __step1(self):\n",
        "        \"\"\"\n",
        "        For each row of the matrix, find the smallest element and\n",
        "        subtract it from every element in its row. Go to Step 2.\n",
        "        \"\"\"\n",
        "        n = self.n\n",
        "        for i in range(n):\n",
        "            minval = min(self.C[i])\n",
        "            # Find the minimum value for this row and subtract that minimum\n",
        "            # from every element in the row.\n",
        "            for j in range(n):\n",
        "                self.C[i][j] -= minval\n",
        "\n",
        "        return 2\n",
        "\n",
        "    def __step2(self):\n",
        "        \"\"\"\n",
        "        Find a zero (Z) in the resulting matrix. If there is no starred\n",
        "        zero in its row or column, star Z. Repeat for each element in the\n",
        "        matrix. Go to Step 3.\n",
        "        \"\"\"\n",
        "        n = self.n\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                if (self.C[i][j] == 0) and \\\n",
        "                   (not self.col_covered[j]) and \\\n",
        "                   (not self.row_covered[i]):\n",
        "                    self.marked[i][j] = 1\n",
        "                    self.col_covered[j] = True\n",
        "                    self.row_covered[i] = True\n",
        "\n",
        "        self.__clear_covers()\n",
        "        return 3\n",
        "\n",
        "    def __step3(self):\n",
        "        \"\"\"\n",
        "        Cover each column containing a starred zero. If K columns are\n",
        "        covered, the starred zeros describe a complete set of unique\n",
        "        assignments. In this case, Go to DONE, otherwise, Go to Step 4.\n",
        "        \"\"\"\n",
        "        n = self.n\n",
        "        count = 0\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                if self.marked[i][j] == 1:\n",
        "                    self.col_covered[j] = True\n",
        "                    count += 1\n",
        "\n",
        "        if count >= n:\n",
        "            step = 7 # done\n",
        "        else:\n",
        "            step = 4\n",
        "\n",
        "        return step\n",
        "\n",
        "    def __step4(self):\n",
        "        \"\"\"\n",
        "        Find a noncovered zero and prime it. If there is no starred zero\n",
        "        in the row containing this primed zero, Go to Step 5. Otherwise,\n",
        "        cover this row and uncover the column containing the starred\n",
        "        zero. Continue in this manner until there are no uncovered zeros\n",
        "        left. Save the smallest uncovered value and Go to Step 6.\n",
        "        \"\"\"\n",
        "        step = 0\n",
        "        done = False\n",
        "        row = -1\n",
        "        col = -1\n",
        "        star_col = -1\n",
        "        while not done:\n",
        "            (row, col) = self.__find_a_zero()\n",
        "            if row < 0:\n",
        "                done = True\n",
        "                step = 6\n",
        "            else:\n",
        "                self.marked[row][col] = 2\n",
        "                star_col = self.__find_star_in_row(row)\n",
        "                if star_col >= 0:\n",
        "                    col = star_col\n",
        "                    self.row_covered[row] = True\n",
        "                    self.col_covered[col] = False\n",
        "                else:\n",
        "                    done = True\n",
        "                    self.Z0_r = row\n",
        "                    self.Z0_c = col\n",
        "                    step = 5\n",
        "\n",
        "        return step\n",
        "\n",
        "    def __step5(self):\n",
        "        \"\"\"\n",
        "        Construct a series of alternating primed and starred zeros as\n",
        "        follows. Let Z0 represent the uncovered primed zero found in Step 4.\n",
        "        Let Z1 denote the starred zero in the column of Z0 (if any).\n",
        "        Let Z2 denote the primed zero in the row of Z1 (there will always\n",
        "        be one). Continue until the series terminates at a primed zero\n",
        "        that has no starred zero in its column. Unstar each starred zero\n",
        "        of the series, star each primed zero of the series, erase all\n",
        "        primes and uncover every line in the matrix. Return to Step 3\n",
        "        \"\"\"\n",
        "        count = 0\n",
        "        path = self.path\n",
        "        path[count][0] = self.Z0_r\n",
        "        path[count][1] = self.Z0_c\n",
        "        done = False\n",
        "        while not done:\n",
        "            row = self.__find_star_in_col(path[count][1])\n",
        "            if row >= 0:\n",
        "                count += 1\n",
        "                path[count][0] = row\n",
        "                path[count][1] = path[count-1][1]\n",
        "            else:\n",
        "                done = True\n",
        "\n",
        "            if not done:\n",
        "                col = self.__find_prime_in_row(path[count][0])\n",
        "                count += 1\n",
        "                path[count][0] = path[count-1][0]\n",
        "                path[count][1] = col\n",
        "\n",
        "        self.__convert_path(path, count)\n",
        "        self.__clear_covers()\n",
        "        self.__erase_primes()\n",
        "        return 3\n",
        "\n",
        "    def __step6(self):\n",
        "        \"\"\"\n",
        "        Add the value found in Step 4 to every element of each covered\n",
        "        row, and subtract it from every element of each uncovered column.\n",
        "        Return to Step 4 without altering any stars, primes, or covered\n",
        "        lines.\n",
        "        \"\"\"\n",
        "        minval = self.__find_smallest()\n",
        "        for i in range(self.n):\n",
        "            for j in range(self.n):\n",
        "                if self.row_covered[i]:\n",
        "                    self.C[i][j] += minval\n",
        "                if not self.col_covered[j]:\n",
        "                    self.C[i][j] -= minval\n",
        "        return 4\n",
        "\n",
        "    def __find_smallest(self):\n",
        "        \"\"\"Find the smallest uncovered value in the matrix.\"\"\"\n",
        "        minval = sys.maxsize\n",
        "        for i in range(self.n):\n",
        "            for j in range(self.n):\n",
        "                if (not self.row_covered[i]) and (not self.col_covered[j]):\n",
        "                    if minval > self.C[i][j]:\n",
        "                        minval = self.C[i][j]\n",
        "        return minval\n",
        "\n",
        "    def __find_a_zero(self):\n",
        "        \"\"\"Find the first uncovered element with value 0\"\"\"\n",
        "        row = -1\n",
        "        col = -1\n",
        "        i = 0\n",
        "        n = self.n\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            j = 0\n",
        "            while True:\n",
        "                if (self.C[i][j] == 0) and \\\n",
        "                   (not self.row_covered[i]) and \\\n",
        "                   (not self.col_covered[j]):\n",
        "                    row = i\n",
        "                    col = j\n",
        "                    done = True\n",
        "                j += 1\n",
        "                if j >= n:\n",
        "                    break\n",
        "            i += 1\n",
        "            if i >= n:\n",
        "                done = True\n",
        "\n",
        "        return (row, col)\n",
        "\n",
        "    def __find_star_in_row(self, row):\n",
        "        \"\"\"\n",
        "        Find the first starred element in the specified row. Returns\n",
        "        the column index, or -1 if no starred element was found.\n",
        "        \"\"\"\n",
        "        col = -1\n",
        "        for j in range(self.n):\n",
        "            if self.marked[row][j] == 1:\n",
        "                col = j\n",
        "                break\n",
        "\n",
        "        return col\n",
        "\n",
        "    def __find_star_in_col(self, col):\n",
        "        \"\"\"\n",
        "        Find the first starred element in the specified row. Returns\n",
        "        the row index, or -1 if no starred element was found.\n",
        "        \"\"\"\n",
        "        row = -1\n",
        "        for i in range(self.n):\n",
        "            if self.marked[i][col] == 1:\n",
        "                row = i\n",
        "                break\n",
        "\n",
        "        return row\n",
        "\n",
        "    def __find_prime_in_row(self, row):\n",
        "        \"\"\"\n",
        "        Find the first prime element in the specified row. Returns\n",
        "        the column index, or -1 if no starred element was found.\n",
        "        \"\"\"\n",
        "        col = -1\n",
        "        for j in range(self.n):\n",
        "            if self.marked[row][j] == 2:\n",
        "                col = j\n",
        "                break\n",
        "\n",
        "        return col\n",
        "\n",
        "    def __convert_path(self, path, count):\n",
        "        for i in range(count+1):\n",
        "            if self.marked[path[i][0]][path[i][1]] == 1:\n",
        "                self.marked[path[i][0]][path[i][1]] = 0\n",
        "            else:\n",
        "                self.marked[path[i][0]][path[i][1]] = 1\n",
        "\n",
        "    def __clear_covers(self):\n",
        "        \"\"\"Clear all covered matrix cells\"\"\"\n",
        "        for i in range(self.n):\n",
        "            self.row_covered[i] = False\n",
        "            self.col_covered[i] = False\n",
        "\n",
        "    def __erase_primes(self):\n",
        "        \"\"\"Erase all prime markings\"\"\"\n",
        "        for i in range(self.n):\n",
        "            for j in range(self.n):\n",
        "                if self.marked[i][j] == 2:\n",
        "                    self.marked[i][j] = 0\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Functions\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "def make_cost_matrix(profit_matrix, inversion_function):\n",
        "    \"\"\"\n",
        "    Create a cost matrix from a profit matrix by calling\n",
        "    'inversion_function' to invert each value. The inversion\n",
        "    function must take one numeric argument (of any type) and return\n",
        "    another numeric argument which is presumed to be the cost inverse\n",
        "    of the original profit.\n",
        "\n",
        "    This is a static method. Call it like this:\n",
        "\n",
        "    .. python::\n",
        "\n",
        "        cost_matrix = Munkres.make_cost_matrix(matrix, inversion_func)\n",
        "\n",
        "    For example:\n",
        "\n",
        "    .. python::\n",
        "\n",
        "        cost_matrix = Munkres.make_cost_matrix(matrix, lambda x : sys.maxint - x)\n",
        "\n",
        "    :Parameters:\n",
        "        profit_matrix : list of lists\n",
        "            The matrix to convert from a profit to a cost matrix\n",
        "\n",
        "        inversion_function : function\n",
        "            The function to use to invert each entry in the profit matrix\n",
        "\n",
        "    :rtype: list of lists\n",
        "    :return: The converted matrix\n",
        "    \"\"\"\n",
        "    cost_matrix = []\n",
        "    for row in profit_matrix:\n",
        "        cost_matrix.append([inversion_function(value) for value in row])\n",
        "    return cost_matrix\n",
        "\n",
        "def print_matrix(matrix, msg=None):\n",
        "    \"\"\"\n",
        "    Convenience function: Displays the contents of a matrix of integers.\n",
        "\n",
        "    :Parameters:\n",
        "        matrix : list of lists\n",
        "            Matrix to print\n",
        "\n",
        "        msg : str\n",
        "            Optional message to print before displaying the matrix\n",
        "    \"\"\"\n",
        "    import math\n",
        "\n",
        "    if msg is not None:\n",
        "        print(msg)\n",
        "\n",
        "    # Calculate the appropriate format width.\n",
        "    width = 0\n",
        "    for row in matrix:\n",
        "        for val in row:\n",
        "            val_width = int(math.log10(abs(val))) + 1 if val != 0 else 0\n",
        "            width = max(width, val_width)\n",
        "\n",
        "    # Make the format string\n",
        "    format = '%%%dd' % width\n",
        "\n",
        "    # Print the matrix\n",
        "    for row in matrix:\n",
        "        sep = '['\n",
        "        for val in row:\n",
        "            sys.stdout.write(sep + format % val)\n",
        "            sep = ', '\n",
        "        sys.stdout.write(']\\n')\n",
        "\n",
        "# ---------------------------------------------------------------------------\n",
        "# Main\n",
        "# ---------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pass\n",
        "\n",
        "    '''\n",
        "    matrices = [\n",
        "                # Square\n",
        "                ([[400, 150, 400],\n",
        "                  [400, 450, 600],\n",
        "                  [300, 225, 300]],\n",
        "                 850 # expected cost\n",
        "                ),\n",
        "\n",
        "                # Rectangular variant\n",
        "                ([[400, 150, 400, 1],\n",
        "                  [400, 450, 600, 2],\n",
        "                  [300, 225, 300, 3]],\n",
        "                 452 # expected cost\n",
        "                ),\n",
        "\n",
        "                # Square\n",
        "                ([[10, 10,  8],\n",
        "                  [ 9,  8,  1],\n",
        "                  [ 9,  7,  4]],\n",
        "                 18\n",
        "                ),\n",
        "\n",
        "                # Rectangular variant\n",
        "                ([[10, 10,  8, 11],\n",
        "                  [ 9,  8,  1, 1],\n",
        "                  [ 9,  7,  4, 10]],\n",
        "                 15\n",
        "                ),\n",
        "               ]\n",
        "\n",
        "    m = Munkres()\n",
        "    for cost_matrix, expected_total in matrices:\n",
        "        print_matrix(cost_matrix, msg='cost matrix')\n",
        "        indexes = m.compute(cost_matrix)\n",
        "        total_cost = 0\n",
        "        for r, c in indexes:\n",
        "            x = cost_matrix[r][c]\n",
        "            total_cost += x\n",
        "            print('(%d, %d) -> %d' % (r, c, x))\n",
        "        print('lowest cost=%d' % total_cost)\n",
        "        assert expected_total == total_cost\n",
        "\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJE_dmicDZaU",
        "colab_type": "text"
      },
      "source": [
        "This next cell contains the class Association() which controls the association process using the calculation of cost functions and the assignment of Lidar Detections to Video Detections using the Munkres method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0,
          5,
          58
        ],
        "id": "azXC0VaWDZaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # This contains the class Association() from association.py in the associations directory\n",
        "\n",
        "# import numpy as np\n",
        "# import munkres\n",
        "\n",
        "# class Association:\n",
        "#     def __init__(self):\n",
        "#         pass\n",
        "\n",
        "#     # the evaluate cost function receives to arguments:\n",
        "#     # 1 - a dictionary called cost functions with the function method name as the key and the weight as the value\n",
        "#     #\n",
        "#     #     cost_functions = { costs.dist_between_centroids : 0.334,\n",
        "#     #                        costs.dist_lidar_to_y2estimate : 0.333,\n",
        "#     #                        costs.inverse_intersection_over_union : 0.333 }\n",
        "#     #\n",
        "#     # 2 - a dictionary contained in **kwargs with the keys containing the names of the two lists of objects\n",
        "#     #     to be associated (video_detections and lidar_detections) and the values are the lists of objects to be\n",
        "#     #     associated.\n",
        "#     #\n",
        "#     #    kwargs = {'video_detections' : video_detections, 'lidar_detections' : lidar_detections}\n",
        "#     #\n",
        "#     #\n",
        "#     # The evaluate cost function evaluates the costs using methods that are contained in the Costs Class in the\n",
        "#     # costs.py file.\n",
        "#     # The function is called like this:\n",
        "#     #\n",
        "#     #     a = Association()\n",
        "#     #     costs = a.evaluate_cost(cost_functions, **kwargs)\n",
        "#     #\n",
        "#     # each of the elements of the costs array represent the cost value between the\n",
        "#     # i-th video_detection and the j-th lidar_detection where\n",
        "#     # cost (i,j) = weight[0] * cost_function[0](i, j) + weight[1] * cost_function[1](i,j) + ... + weight[n] * cost_function[n](i,j)\n",
        "#     # for n cost functions and weights in the cost_functions dictionary\n",
        "\n",
        "#     def evaluate_cost(self, cost_functions, **kwargs):\n",
        "\n",
        "#         array_size = []\n",
        "#         for k,v in kwargs.items():\n",
        "#             array_size.append(len(v))\n",
        "\n",
        "#         cost = np.zeros((array_size[0], array_size[1]), np.float64 )\n",
        "#         cost_components = []\n",
        "\n",
        "#         for function_name, weight in cost_functions.items():\n",
        "#             cost_component = function_name(**kwargs)\n",
        "#             cost += weight * cost_component\n",
        "#             cost_components.append(cost_component)\n",
        "\n",
        "#         return cost, cost_components\n",
        "\n",
        "#     def compute_munkres(self, cost):\n",
        "#         m = munkres.Munkres()\n",
        "#         assignments = m.compute(cost)\n",
        "#         return assignments\n",
        "\n",
        "\n",
        "# # this is a test of the Association class using the cost methods contained in the Costs class\n",
        "# if __name__ == '__main__':\n",
        "#     pass\n",
        "#     '''\n",
        "#     import src.detection.detection as video_det\n",
        "#     import src.lidar.lidar_detection as lidar_det\n",
        "#     import src.association.costs as costs\n",
        "\n",
        "#     costs = costs.Costs()\n",
        "\n",
        "#     vdet0 = video_det.Detection()\n",
        "#     vdet0.bbox = [412, 375, 486, 421]\n",
        "#     vdet1 = video_det.Detection()\n",
        "#     vdet1.bbox = [762, 374, 799, 408]\n",
        "#     vdet2 = video_det.Detection()\n",
        "#     vdet2.bbox = [913, 338, 1020, 375]\n",
        "#     vdet3 = video_det.Detection()\n",
        "#     vdet3.bbox = [708, 374, 739, 400]\n",
        "#     vdet4 = video_det.Detection()\n",
        "#     vdet4.bbox = [613, 361, 650, 384]\n",
        "#     vdet5 = video_det.Detection()\n",
        "#     vdet5.bbox = [562, 369, 600, 396]\n",
        "#     vdet6 = video_det.Detection()\n",
        "#     vdet6.bbox = [774, 378, 990, 502]\n",
        "#     vdet7 = video_det.Detection()\n",
        "#     vdet7.bbox = [893, 350, 954, 377]\n",
        "#     vdet8 = video_det.Detection()\n",
        "#     vdet8.bbox = [171, 360, 301, 416]\n",
        "\n",
        "#     video_detections = [vdet0, vdet1, vdet2, vdet3, vdet4, vdet5, vdet6, vdet7, vdet8]\n",
        "\n",
        "#     ldet0 = lidar_det.LIDAR_detection(840, 2, 38.3435516357, 0)\n",
        "#     ldet1 = lidar_det.LIDAR_detection(840, 11, 12.4829711914, 0)\n",
        "#     ldet2 = lidar_det.LIDAR_detection(840, 12, 12.714263915999998, 0)\n",
        "#     ldet3 = lidar_det.LIDAR_detection(840, 12, 36.3725891113, 0)\n",
        "#     ldet4 = lidar_det.LIDAR_detection(840, 13, 12.671356201199998, 0)\n",
        "#     ldet5 = lidar_det.LIDAR_detection(840, 15, 12.3006744385, 0)\n",
        "#     lidar_detections = [ldet0, ldet1, ldet2, ldet3, ldet4, ldet5]\n",
        "\n",
        "#     # enter the cost method names as keys in the dictionary and weights as their values\n",
        "#     # the returned costs array will have a number of rows equal to the number of video_detection objects\n",
        "#     # and a number of columns equal to the nubmer of lidar_detection objects.\n",
        "#     #\n",
        "#     # each of the elements of the array represent the cost value between the i-th video_detection and the j-th lidar_detection\n",
        "#     # cost (i,j) = weight[0] * cost_function[0](i, j) + weight[1] * cost_function[1](i,j) + ... + weight[n] * cost_function[n](i,j)\n",
        "#     # for n cost functions and weights in the cost_functions dictionary\n",
        "\n",
        "#     cost_functions = { costs.dist_between_centroids : 0.334,\n",
        "#                        costs.dist_lidar_to_y2estimate : 0.333,\n",
        "#                        costs.inverse_intersection_over_union : 0.333 }\n",
        "\n",
        "#     a = Association()\n",
        "\n",
        "#     # enter the video_detections and lidar_detections lists into the kwargs dictionary\n",
        "#     kwargs = {'video_detections' : video_detections, 'lidar_detections' : lidar_detections}\n",
        "\n",
        "#     # evaluate the costs array by passing the cost_functions dictionary and the kwargs dictionary to the evaluate_costs method\n",
        "#     costs = a.evaluate_cost(cost_functions, **kwargs)\n",
        "\n",
        "#     b = 1\n",
        "#     '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "QZO7mHL8DZaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This contains code to display the current mouse location on the video screen\n",
        "\n",
        "global x_pixel, y_pixel, no_mouse_click_count\n",
        "x_pixel = -1\n",
        "y_pixel = -1\n",
        "max_no_mouse_click_count = 100\n",
        "no_mouse_click_count = max_no_mouse_click_count\n",
        "\n",
        "def mouse_click(event, x, y, flags, param):\n",
        "    global x_pixel, y_pixel, no_mouse_click_count\n",
        "    no_mouse_click_count = max_no_mouse_click_count\n",
        "\n",
        "    if event == cv2.EVENT_MOUSEMOVE:\n",
        "        x_pixel = x\n",
        "        y_pixel = y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "83qgSgV9DZae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This contains code to draw bounding boxes on an imagerobert@verix-6440:~$ cd ~/PycharmProjects/\n",
        "\n",
        "def draw_bboxes(bboxes, img):\n",
        "    \"\"\"\n",
        "    Draw bounding boxes to frame\n",
        "    :param bboxes: list of bboxes in [x1,y1,x2,y2] format\n",
        "    :param img: np.arr\n",
        "ay\n",
        "    :return: image with bboxes drawn\n",
        "    \"\"\"\n",
        "    img = img.copy()\n",
        "    if bboxes is not None and len(bboxes) > 0:\n",
        "        for i, bb in enumerate(bboxes):\n",
        "            cv2.rectangle(img, (bb[0], bb[1]), (bb[2], bb[3]), (0, 255, 0), 2)\n",
        "\n",
        "    return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "2NJ4eb8EDZai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is the main loop for processing and testing associations\n",
        "\n",
        "def run_association_test(manual_test, read_file = False):\n",
        "\n",
        "    # This contains all of the imports needed for running the association tests\n",
        "\n",
        "    import os\n",
        "    import cv2\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from src.detection.car_detector_tf_v2 import CarDetectorTFV2\n",
        "    from src.detection.detection import Detection\n",
        "    from src.lidar.lidar_detection import LIDAR_detection\n",
        "    from src.association.association import Association\n",
        "    from src.association.costs import Costs\n",
        "    import src.util.calibration_kitti as cal\n",
        "    import math\n",
        "    import pykitti\n",
        "    import datetime\n",
        "    #from tqdm import tqdm\n",
        "    from tqdm import tqdm_notebook\n",
        "    \n",
        "    \n",
        "    # This contains all of the defines and hyperparameters neededfor the associations tests\n",
        "    WRITE_VIDEO_FILE = False\n",
        "    WRITE_DATA_FILE = False\n",
        "\n",
        "    # set USE_DETECTOR to True to use the Yolo CNN or False to use the ground truth for the Video Detections\n",
        "    USE_DETECTOR = True\n",
        "    # the minimum detection confidence level for the Yolo CNN\n",
        "    CONFIDENCE_THRESHOLD = 0.8\n",
        "\n",
        "\n",
        "    # the run control variables\n",
        "    PAUSE = False\n",
        "    DISP_LIDAR = False\n",
        "    DISP_DET = False\n",
        "    DISP_ASSOC = True\n",
        "    DISP_ZONES = True\n",
        "    DISP_TRUTH = True\n",
        "    DISP_RESULTS = True\n",
        "    SLOW = False\n",
        "  \n",
        "    global x_pixel, y_pixel, no_mouse_click_count\n",
        "    x_pixel = -1\n",
        "    y_pixel = -1\n",
        "    max_no_mouse_click_count = 100\n",
        "    no_mouse_click_count = max_no_mouse_click_count\n",
        "\n",
        "    def mouse_click(event, x, y, flags, param):\n",
        "        global x_pixel, y_pixel, no_mouse_click_count\n",
        "        no_mouse_click_count = max_no_mouse_click_count\n",
        "\n",
        "        if event == cv2.EVENT_MOUSEMOVE:\n",
        "            x_pixel = x\n",
        "            y_pixel = y\n",
        "    \n",
        "    # the locations and dates of the video and lidat data files\n",
        "    PWD = './'\n",
        "    DATA_DATE = '2011_09_26'\n",
        "    RUN_NUMBER = '0015'\n",
        "    DATA_DIR = '../data'\n",
        "\n",
        "    video_frame_lag = 0\n",
        "    dist_thresh = 0.2 # set higher to allow less accurate lidar readings to be labeled as correct\n",
        "\n",
        "    # This contains the setup for the lidar detections\n",
        "\n",
        "    lidar_left = cal.SEG_TO_PIXEL_LEFT[0]\n",
        "    lidar_right = cal.SEG_TO_PIXEL_RIGHT[15]\n",
        "    lidar_top = cal.SEG_TO_PIXEL_TOP\n",
        "    lidar_bottom = cal.SEG_TO_PIXEL_BOTTOM\n",
        "\n",
        "    # read the lidar data\n",
        "    m16 = pd.read_csv('{}/{}/{}_filtered.csv'.format(DATA_DIR, DATA_DATE, RUN_NUMBER ), skiprows=2)\n",
        "\n",
        "    # read the ground truth from the tracklets data\n",
        "    gt_df = pd.read_csv('{}/{}'.format(DATA_DIR, '2011_09_26_drive_0015_sync_converted-tracklets.csv'))\n",
        "    gt_df['dist'] = gt_df['dist'] * cal.cal['M_TO_FT']\n",
        "    # remove all objects that are not vehicles\n",
        "    gt_df = gt_df[(gt_df['label']=='Car') | (gt_df['label']=='Truck') | (gt_df['label']=='Van')]\n",
        "    # remove all objects outside the range of the lidar detector\n",
        "    gt_df = gt_df[(gt_df['dist']>=30) & (gt_df['dist'] <= 140)]\n",
        "    #remove all objects outside of the lidar fov\n",
        "    gt_df = gt_df[gt_df['x1'] <= lidar_right]\n",
        "    gt_df = gt_df[gt_df['x2'] >= lidar_left]\n",
        "    gt_df = gt_df[gt_df['y1'] <= lidar_bottom]\n",
        "    gt_df = gt_df[gt_df['y2'] >= lidar_top]\n",
        "\n",
        "    \n",
        "    column_names_2 = ['run_num','use_detector', 'max_cost', 'w0', 'w1', 'w2', 'total_associations', 'accuracy', 'precision', 'recall', 'total_possible_associations', 'true_pos', 'false_pos', 'false_neg']\n",
        "    #test_results = pd.read_csv('test_runs.csv')\n",
        "\n",
        "    #manual_test = [0, False, 1, 0.95, 0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "    test_results = pd.DataFrame([manual_test], columns=column_names_2)\n",
        "\n",
        "\n",
        "    # create a class to access the kitti dataset\n",
        "    kitti_dataset = pykitti.raw(base_path='../data/', date=DATA_DATE, drive=RUN_NUMBER)\n",
        "\n",
        "    if USE_DETECTOR:\n",
        "        detector = CarDetectorTFV2()\n",
        "\n",
        "    first_frame = True\n",
        "\n",
        "    run_num = 0\n",
        "\n",
        "    for run_num in tqdm_notebook(range(len(test_results))):\n",
        "\n",
        "        total_possible_associations = 0\n",
        "        true_pos = 0\n",
        "        false_pos = 0\n",
        "        false_neg = 0\n",
        "\n",
        "        USE_DETECTOR = test_results.loc[(test_results['run_num'] == run_num)].use_detector.bool()\n",
        "\n",
        "\n",
        "\n",
        "        max_cost = np.float(test_results.loc[test_results['run_num'] == run_num].max_cost)\n",
        "        w0 = np.float(test_results.loc[test_results['run_num'] == run_num].w0)\n",
        "        w1 = np.float(test_results.loc[test_results['run_num'] == run_num].w1)\n",
        "        w2 = np.float(test_results.loc[test_results['run_num'] == run_num].w2)\n",
        "\n",
        "        weights = [w0, w1, w2]\n",
        "\n",
        "        column_names = ['frame', 'video_det_index', 'lidar_det_index', 'gt_index', 'lidar_dist', 'gt_dist', 'cost',\n",
        "                        'correct', 'max_cost', 'dist_thresh', 'w0', 'c0', 'w1', 'c1', 'w2', 'c2', ]\n",
        "        associations_record = pd.DataFrame([], columns=column_names)\n",
        "\n",
        "        for frame_num, frame_filename in enumerate(kitti_dataset.cam2_files):\n",
        "            new_frame = True\n",
        "            frame = cv2.imread(frame_filename)\n",
        "            success = frame.any()\n",
        "            frame_draw = frame.copy()\n",
        "            if not success:\n",
        "                print('no frame')\n",
        "                break\n",
        "\n",
        "            if first_frame:\n",
        "                cv2.namedWindow('draw_frame')\n",
        "                cv2.setMouseCallback('draw_frame', mouse_click)\n",
        "                first_frame = False\n",
        "\n",
        "\n",
        "            # get the ground truth values\n",
        "            gt_current_frame = gt_df.loc[gt_df['frame_number'] == frame_num]\n",
        "\n",
        "\n",
        "            # fill in the list of detections\n",
        "            bboxes = []\n",
        "            c = Costs()\n",
        "\n",
        "            if frame_num == 7:\n",
        "                a = 1\n",
        "\n",
        "\n",
        "            if USE_DETECTOR:\n",
        "                # get the video detections\n",
        "                \n",
        "                bbs, class_names, confidences = detector.detect(img=frame, return_class_scores=True)\n",
        "                for i, bb in enumerate(bbs):\n",
        "                    # ensure bb is inside the window\n",
        "                    bbs[i][0] = max(bb[0],0)\n",
        "                    bbs[i][1] = max(bb[1],0)\n",
        "                    bbs[i][2] = min(bb[2],cal.cal['X_RESOLUTION'])\n",
        "                    bbs[i][3] = min(bb[3],cal.cal['Y_RESOLUTION'])\n",
        "                n = len(class_names)\n",
        "                eliminate_flag = np.zeros(n,np.int)\n",
        "                for i, (bbox, class_name, confidence) in enumerate(zip(bbs, class_names, confidences)):\n",
        "                    # filter out bounding boxes that do not intersect with the lidar zone and are not vehicles\n",
        "                    if class_name not in ['car', 'truck', 'bus'] or confidence <= CONFIDENCE_THRESHOLD:\n",
        "                        eliminate_flag[i] = 1\n",
        "                    if (bbox[1] > lidar_bottom or bbox[3] < lidar_top or bbox[2] < lidar_left or bbox[0] > lidar_right):\n",
        "                        eliminate_flag[i] = 1\n",
        "                #remove the items from bbs, class_names and confidences\n",
        "                new_bbs = []; new_class_names = []; new_confidences = [];\n",
        "                for ii in range(n):\n",
        "                    if eliminate_flag[ii] == 0:\n",
        "                        new_bbs.append(bbs[ii])\n",
        "                        new_class_names.append(class_names[ii])\n",
        "                        new_confidences.append(confidences[ii])\n",
        "                bbs = new_bbs\n",
        "                class_names = new_class_names\n",
        "                confidences = new_confidences\n",
        "\n",
        "                n = len(class_names)\n",
        "                eliminate_flag = np.zeros(n,np.int)\n",
        "\n",
        "                #eliminate redundant detections - iou greater that 0.7 and different class_name\n",
        "                for ii in range(n):\n",
        "                    for jj in range(n):\n",
        "                        if ii < jj and c._iou(bbs[ii],bbs[jj]) >= 0.7 and class_names[ii] != class_names[jj]:\n",
        "                            eliminate_flag[jj] = 1\n",
        "\n",
        "                #remove the redundant items from bbs, class_names and confidences\n",
        "                new_bbs = []; new_class_names = []; new_confidences = [];\n",
        "                for ii in range(n):\n",
        "                    if eliminate_flag[ii] == 0:\n",
        "                        new_bbs.append(bbs[ii])\n",
        "                        new_class_names.append(class_names[ii])\n",
        "                        new_confidences.append(confidences[ii])\n",
        "                bbs = new_bbs\n",
        "                class_names = new_class_names\n",
        "                confidences = new_confidences\n",
        "                # only append what's left\n",
        "                for i, (bbox, class_name, confidence) in enumerate(zip(bbs, class_names, confidences)):\n",
        "                    bboxes.append(bbox)\n",
        "\n",
        "            else:\n",
        "                # get the bounding boxes from the ground truth data\n",
        "                gt_dist = []\n",
        "                for i, gt in enumerate(gt_current_frame.values):\n",
        "                    bboxes.append([gt[1], gt[2], gt[3], gt[4]])\n",
        "                    gt_dist.append(gt[6])\n",
        "                    total_possible_associations += 1\n",
        "\n",
        "            video_detections = []\n",
        "            if bboxes is not None and len(bboxes) > 0:\n",
        "                for i, bb in enumerate(bboxes):\n",
        "                    det = Detection()\n",
        "                    det.bbox = np.array([bb[0], bb[1], bb[2], bb[3]])\n",
        "                    det.frame_id = frame_num\n",
        "                    video_detections.append(det)\n",
        "\n",
        "\n",
        "            # get the lidar values\n",
        "            lidar_vals = m16.loc[m16['frame'] == frame_num-video_frame_lag]\n",
        "\n",
        "            lidar_detections = []\n",
        "            for ii in range(len(lidar_vals)):\n",
        "                if lidar_vals.iloc[ii,5] >= 30 and lidar_vals.iloc[ii,5] <= 140:\n",
        "                    lidar_detection = LIDAR_detection(frame_num,int(lidar_vals.iloc[ii,4]),lidar_vals.iloc[ii,5],lidar_vals.iloc[ii,6])\n",
        "\n",
        "                    lidar_detections.append(lidar_detection)\n",
        "\n",
        "\n",
        "\n",
        "            # perform the associations task\n",
        "            if len(lidar_detections) > 0 and len(video_detections) > 0:\n",
        "                associations = []\n",
        "                costs = Costs()\n",
        "\n",
        "                # total_cost(i,j) = w_0 * cost_function_0(i,j) + w_1 * cost_function_1(i,j) + .. + w_n * cost_function_n(i,j)\n",
        "                cost_functions = {costs.dist_between_centroids: weights[0],\n",
        "                                  costs.dist_lidar_to_y2estimate: weights[1],\n",
        "                                  costs.inverse_intersection_over_union: weights[2]}\n",
        "\n",
        "                a = Association()\n",
        "\n",
        "                # enter the video_detections and lidar_detections lists into the kwargs dictionary\n",
        "                kwargs = {'video_detections': video_detections, 'lidar_detections': lidar_detections}\n",
        "\n",
        "                # evaluate the costs array by passing the cost_functions dictionary and the kwargs dictionary to the evaluate_costs method\n",
        "                costs, cost_components = a.evaluate_cost(cost_functions, **kwargs)\n",
        "\n",
        "                original_costs = costs.copy()\n",
        "\n",
        "                c_shape = np.shape(costs)\n",
        "                rows = c_shape[0]\n",
        "                cols = c_shape[1]\n",
        "                if rows <= cols:\n",
        "                    assignments = a.compute_munkres(costs)\n",
        "#                     costs_T = np.transpose(costs)\n",
        "#                     import pdb; pdb.set_trace()\n",
        "#                     assignments_T = a.compute_munkres(costs_T)\n",
        "#                     assignments = []\n",
        "\n",
        "#                     for i, assignment in enumerate(assignments_T):\n",
        "#                         assignments.append((assignment[1],assignment[0]))\n",
        "\n",
        "                if len(assignments) != min(len(video_detections), len(lidar_detections)):\n",
        "                    a = 1\n",
        "                #determine if the associations are correct\n",
        "\n",
        "\n",
        "                if USE_DETECTOR:\n",
        "                    for i, gt in enumerate(gt_current_frame.values):\n",
        "                        total_possible_associations += 1\n",
        "                        bb_gt = [gt[1], gt[2], gt[3], gt[4]]\n",
        "                        for j, assignment in enumerate(assignments):\n",
        "                            if original_costs[assignment[0], assignment[1]] < max_cost:\n",
        "                                bb_v = video_detections[assignment[0]].bbox\n",
        "                                iou = c._iou(bb_gt, bb_v)\n",
        "                                if iou > 0:\n",
        "                                    dist_diff = abs(lidar_detections[assignment[1]].dist - gt[6])\n",
        "                                    if dist_diff < dist_thresh * gt[6]:\n",
        "                                        new_row = [frame_num, assignment[0], assignment[1], i,\n",
        "                                                   lidar_detections[assignment[1]].dist, gt[6],\n",
        "                                                   original_costs[assignment[0], assignment[1]], 'True', max_cost,\n",
        "                                                   dist_thresh, weights[0],\n",
        "                                                   cost_components[0][assignment[0], assignment[1]], weights[1],\n",
        "                                                   cost_components[1][assignment[0], assignment[1]], weights[2],\n",
        "                                                   cost_components[2][assignment[0], assignment[1]]]\n",
        "                                        true_pos += 1\n",
        "                                    else:\n",
        "                                        new_row = [frame_num, assignment[0], assignment[1], i,\n",
        "                                                   lidar_detections[assignment[1]].dist, gt[6],\n",
        "                                                   original_costs[assignment[0], assignment[1]], 'False', max_cost,\n",
        "                                                   dist_thresh, weights[0],\n",
        "                                                   cost_components[0][assignment[0], assignment[1]], weights[1],\n",
        "                                                   cost_components[1][assignment[0], assignment[1]], weights[2],\n",
        "                                                   cost_components[2][assignment[0], assignment[1]]]\n",
        "                                        false_pos += 1\n",
        "                                    row_num = len(associations_record)\n",
        "                                else:\n",
        "                                    new_row = [frame_num, assignment[0], assignment[1], i,\n",
        "                                               lidar_detections[assignment[1]].dist, gt[6],\n",
        "                                               original_costs[assignment[0], assignment[1]], 'false_neg_iouzero', max_cost,\n",
        "                                               dist_thresh, weights[0],\n",
        "                                               cost_components[0][assignment[0], assignment[1]], weights[1],\n",
        "                                               cost_components[1][assignment[0], assignment[1]], weights[2],\n",
        "                                               cost_components[2][assignment[0], assignment[1]]]\n",
        "                                    false_neg += 1\n",
        "                            else:\n",
        "                                new_row = [frame_num, assignment[0], assignment[1], i,\n",
        "                                           lidar_detections[assignment[1]].dist, gt[6],\n",
        "                                           original_costs[assignment[0], assignment[1]], 'false_neg_max_cost', max_cost,\n",
        "                                           dist_thresh, weights[0],\n",
        "                                           cost_components[0][assignment[0], assignment[1]], weights[1],\n",
        "                                           cost_components[1][assignment[0], assignment[1]], weights[2],\n",
        "                                           cost_components[2][assignment[0], assignment[1]]]\n",
        "                                false_neg += 1\n",
        "                            associations_record.loc[row_num] = new_row\n",
        "\n",
        "                else:\n",
        "                    cols = ['frame', 'video_det_index', 'lidar_det_index', 'gt_index', 'lidar_dist', 'gt_dist', 'cost', 'correct']\n",
        "                    for assignment in assignments:\n",
        "                        if original_costs[assignment[0],assignment[1]] < max_cost:\n",
        "                            dist_diff = abs(lidar_detections[assignment[1]].dist - gt_dist[assignment[0]])\n",
        "                            if dist_diff < dist_thresh * gt_dist[assignment[0]]:\n",
        "                                new_row = [frame_num, assignment[0], assignment[1], i, lidar_detections[assignment[1]].dist,\n",
        "                                           gt_dist[assignment[0]], original_costs[assignment[0], assignment[1]], 'True', max_cost, dist_thresh,\n",
        "                                           weights[0], cost_components[0][assignment[0], assignment[1]], weights[1],\n",
        "                                           cost_components[1][assignment[0], assignment[1]], weights[2],\n",
        "                                           cost_components[2][assignment[0], assignment[1]]]\n",
        "                                true_pos += 1\n",
        "                            else:\n",
        "                                new_row = [frame_num, assignment[0], assignment[1], i, lidar_detections[assignment[1]].dist,\n",
        "                                           gt_dist[assignment[0]], original_costs[assignment[0], assignment[1]], 'False', max_cost, dist_thresh,\n",
        "                                           weights[0], cost_components[0][assignment[0], assignment[1]], weights[1],\n",
        "                                           cost_components[1][assignment[0], assignment[1]], weights[2],\n",
        "                                           cost_components[2][assignment[0], assignment[1]]]\n",
        "                                false_pos += 1\n",
        "                            row_num = len(associations_record)       \n",
        "                        else:\n",
        "                            new_row = [frame_num, assignment[0], assignment[1], i, lidar_detections[assignment[1]].dist,\n",
        "                                       gt_dist[assignment[0]], original_costs[assignment[0], assignment[1]], 'false_neg_maxcost',\n",
        "                                       max_cost, dist_thresh,\n",
        "                                       weights[0], cost_components[0][assignment[0], assignment[1]], weights[1],\n",
        "                                       cost_components[1][assignment[0], assignment[1]], weights[2],\n",
        "                                       cost_components[2][assignment[0], assignment[1]]]\n",
        "                            false_neg += 1\n",
        "                        associations_record.loc[row_num] = new_row\n",
        "\n",
        "            #display the frame once if not PAUSE; continuously if PAUSE\n",
        "            while new_frame or PAUSE:\n",
        "                new_frame = False # only go through once unless PAUSE\n",
        "\n",
        "                # draw vertical line in center of image\n",
        "                cv2.line(frame_draw, (int(cal.cal['X_CENTER']), 0), (int(cal.cal['X_CENTER']), int(frame_draw.shape[0])),\n",
        "                         (255, 0, 255), 1)\n",
        "                cv2.line(frame_draw, (0, int(cal.cal['Y_HORIZON'])), (int(frame_draw.shape[1]), int(cal.cal['Y_HORIZON'])),\n",
        "                         (255, 0, 255), 1)\n",
        "                cv2.putText(frame_draw, 'frame: {0:0.0f}'.format(frame_num), (0, 25), 1, 2, (0, 0, 255), 2)\n",
        "\n",
        "                if DISP_DET: # show video detections in green\n",
        "                    for video_detection in video_detections:\n",
        "                        cv2.rectangle(frame_draw, (int(bb[0]), int(bb[1])), (int(bb[2]), int(bb[3])), (0, 255, 0), 2)\n",
        "\n",
        "                if DISP_LIDAR: # show lidar ideal bounding boxes in yellow\n",
        "                    for lidar_detection in lidar_detections:\n",
        "                        lidar_dist = lidar_detection.dist\n",
        "                        bb = lidar_detection.bb\n",
        "                        cv2.rectangle(img=frame_draw, pt1=(int(bb[0]), int(bb[1])), pt2=(int(bb[2]), int(bb[3])),\n",
        "                                      color=(0, 255, 255), thickness=2)\n",
        "                        cv2.putText(frame_draw, '{0:0.2f}'.format(lidar_dist), (int(bb[0]), int(bb[1])), 1, 1, (0, 0, 255), 2)\n",
        "\n",
        "                if DISP_ASSOC: # show associations in blue and red connected by a yellow line\n",
        "                    if len(lidar_detections) > 0 and len(video_detections) > 0:\n",
        "                        for assignment in assignments:\n",
        "                            if original_costs[assignment[0],assignment[1]] <= max_cost:\n",
        "                                bb_v = video_detections[assignment[0]].bbox\n",
        "                                dist_est = float(video_detections[assignment[0]].dist_est_y2[assignment[1]])\n",
        "                                lidar_dist = lidar_detections[assignment[1]].dist\n",
        "                                cv2.rectangle(img=frame_draw, pt1=(int(bb_v[0]),int(bb_v[1])), pt2=(int(bb_v[2]),int(bb_v[3])), color=(255,0,0), thickness=2)\n",
        "        #                        cv2.putText(frame_draw, '{0:0.0f}'.format(assignment[0]), (int(bb_v[0]),int(bb_v[1])), 1, 1, (255, 0, 0), 2)\n",
        "        #                        cv2.putText(frame_draw, '{0:0.2f}'.format(dist_est), (int(bb_v[0]-30), int(bb_v[3]+25)), 1, 1, (255, 0, 0), 2)\n",
        "                                bb_l = lidar_detections[assignment[1]].bb\n",
        "                                cv2.rectangle(img=frame_draw, pt1=(int(bb_l[0]),int(bb_l[1])), pt2=(int(bb_l[2]),int(bb_l[3])), color=(0,0,255), thickness=2)\n",
        "        #                        cv2.putText(frame_draw, '{0:0.0f}'.format(assignment[1]), (int(bb_l[0]),int(bb_l[1])), 1, 1, (0, 0, 255), 2)\n",
        "                                cv2.putText(frame_draw, '{0:0.2f}'.format(lidar_dist), (int(bb_l[0]),int(bb_l[3])+25), 1, 1, (0, 0, 255), 2)\n",
        "                                cv2.line(img=frame_draw, pt1=(int(bb_v[0]),int(bb_v[1])), pt2=(int(bb_l[0]),int(bb_l[1])), color=(0,255,255), thickness=2)\n",
        "\n",
        "                if DISP_ZONES: # show the lidar zone boundaries in black\n",
        "                    y1 = int(cal.SEG_TO_PIXEL_TOP)\n",
        "                    y2 = int(cal.SEG_TO_PIXEL_BOTTOM)\n",
        "                    for i in range(16):\n",
        "                        x = int(cal.SEG_TO_PIXEL_LEFT[i])\n",
        "                        cv2.line(frame_draw, (x, y1), (x, y2), (0, 0, 0), thickness=1)\n",
        "                        cv2.line(frame_draw, (x - 5, y1), (x + 5, y1), (0, 0, 0), thickness=1)\n",
        "                        cv2.line(frame_draw, (x - 5, y2), (x + 5, y2), (0, 0, 0), thickness=1)\n",
        "\n",
        "                    x = int(cal.SEG_TO_PIXEL_RIGHT[i])\n",
        "                    cv2.line(frame_draw, (x, y1), (x, y2), (0, 0, 0), thickness=1)\n",
        "                    cv2.line(frame_draw, (x - 5, y1), (x + 5, y1), (0, 0, 0), thickness=1)\n",
        "                    cv2.line(frame_draw, (x - 5, y2), (x + 5, y2), (0, 0, 0), thickness=1)\n",
        "\n",
        "                if DISP_TRUTH: # show the ground truth bboxes and dist\n",
        "                    for i in range(len(gt_current_frame)):\n",
        "                        x1, y1, x2, y2, label, dist = gt_current_frame.iloc[i,1:]\n",
        "                        if not (x2 < lidar_left or x1 > lidar_right or y1 > lidar_bottom or y2 < lidar_top):\n",
        "                            cv2.rectangle(img=frame_draw, pt1=(int(x1), int(y1)), pt2=(int(x2), int(y2)),color=(0, 255, 0), thickness=2)\n",
        "                            cv2.putText(frame_draw, '{0:0.1f}'.format(dist), (int(x1), int(y1)), 1, 1,(0, 255, 0), 2)\n",
        "\n",
        "                # show the nouse coordinates\n",
        "                if x_pixel >= 0 and no_mouse_click_count > 0:\n",
        "                    cv2.putText(frame_draw, '({0:0.0f}, {1:0.0f})'.format(x_pixel, y_pixel),\n",
        "                                (cal.cal['X_RESOLUTION'] - 120, 15), 1, 1, (0, 0, 255), 2)\n",
        "                    no_mouse_click_count -= 1\n",
        "\n",
        "                if DISP_RESULTS:\n",
        "                    pass\n",
        "\n",
        "                cv2.putText(frame_draw, 'frame: {0:0.0f}'.format(frame_num), (0, 25), 1, 2, (0, 0, 255), 2)\n",
        "                cv2.imshow('draw_frame', frame_draw)\n",
        "\n",
        "                if SLOW:\n",
        "                    key = cv2.waitKey(1000) & 0xFF\n",
        "                else:\n",
        "                    key = cv2.waitKey(30) & 0xFF\n",
        "\n",
        "                if frame_num == 212:\n",
        "                    a = 1\n",
        "\n",
        "                if key == ord('q') or key == 27:\n",
        "                    exit(0)\n",
        "                if key == ord('p') or key == ord('P'):\n",
        "                    PAUSE = not PAUSE\n",
        "                if key == ord('l') or key == ord('L'):\n",
        "                    DISP_LIDAR = not DISP_LIDAR\n",
        "                if key == ord('d') or key == ord('D'):\n",
        "                    DISP_DET = not DISP_DET\n",
        "                if key == ord('a') or key == ord('A'):\n",
        "                    DISP_ASSOC = not DISP_ASSOC\n",
        "                if key == ord('s') or key == ord('S'):\n",
        "                    SLOW = not SLOW\n",
        "                if key == ord('z') or key == ord('Z'):\n",
        "                    DISP_ZONES = not DISP_ZONES\n",
        "                if key == ord('t') or key == ord('T'):\n",
        "                    DISP_TRUTH = not DISP_TRUTH\n",
        "\n",
        "        false_neg = total_possible_associations - (true_pos + false_pos)\n",
        "        accuracy = true_pos / total_possible_associations\n",
        "        if true_pos + false_pos > 0:\n",
        "            precision = true_pos / (true_pos + false_pos)\n",
        "        else:\n",
        "            precision = np.nan\n",
        "\n",
        "        if true_pos + false_neg > 0:\n",
        "            recall = true_pos / (true_pos + false_neg)\n",
        "        else:\n",
        "            recall = np.nan\n",
        "\n",
        "        now = datetime.datetime.now()\n",
        "        filename = 'results_{0:04d}.csv'.format(run_num)\n",
        "\n",
        "        associations_record.to_csv(filename, index=False)\n",
        "\n",
        "        print('run: {0:0.0f}, accy: {1:0.3f}, prec: {2:0.3f}, recall: {3:0.3f}, total_assoc: {4:0.0f}, total_poss_assoc: {5:0.0f}, true_pos: {6:0.0f}, '\n",
        "              'false_pos: {7:0.0f}, false_neg: {8:0.0f}, use_detector:{9:}, max_cost: {10:0.3f}, w0: {11:0.3f}, w1: {12:0.3f}, '\n",
        "              'w2: {13:0.3f}'.format(run_num, accuracy, precision, recall, len(associations_record), total_possible_associations, true_pos, false_pos, false_neg, str(USE_DETECTOR), max_cost, weights[0], weights[1], weights[2]))\n",
        "\n",
        "        #column_names_2 = ['run_num', 'max_cost', 'w0', 'w1', 'w2', 'total_associations', 'accuracy',\n",
        "        #                  'total_possible_associations', 'true_pos', 'false_pos', 'false_neg']\n",
        "\n",
        "        test_results.iloc[run_num,6] = len(associations_record)\n",
        "        test_results.iloc[run_num,7] = accuracy\n",
        "        test_results.iloc[run_num,8] = precision\n",
        "        test_results.iloc[run_num,9] = recall\n",
        "        test_results.iloc[run_num,10] = total_possible_associations\n",
        "        test_results.iloc[run_num,11] = true_pos\n",
        "        test_results.iloc[run_num,12] = false_pos\n",
        "        test_results.iloc[run_num,13] = false_neg\n",
        "\n",
        "    filename = 'test_results_' + str(now) + '.csv'\n",
        "    test_results.to_csv(filename)\n",
        "    cv2.waitKey(1)\n",
        "    cv2.destroyAllWindows()\n",
        "    cv2.waitKey(1)\n",
        "\n",
        "    print('Run Complete!')\n",
        "    \n",
        "    return test_results\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXMpoSaJDZan",
        "colab_type": "text"
      },
      "source": [
        "### Testing Definitions\n",
        "\n",
        "The following definitions are used to evaluate the accuracy of the association process:\n",
        "\n",
        "\n",
        "__True Positive:__\n",
        "\n",
        "If: an association has a video detection bounding box that intersects with a Ground Truth bounding box __AND__ has a cost value less than the hyper-parameter max_cost __AND__ has a lidar distance value __within__ the hyper-parameter __dist_thresh__ (percentage) of the Ground Truth distance \n",
        "\n",
        "Then: it is labeled a __True Positive__ association (true_pos)\n",
        "\n",
        ">These __True Positive__ associations are the correct associations with a video detection and lidar reading that is related with high confidence to a labeled Ground Truth object\n",
        "\n",
        "__False Positive - Video Detector:__\n",
        "\n",
        "If: an association is made with a video detection bounding box that does not intersect a ground truth bounding box \n",
        "\n",
        "Then: the association is labeled a __False Positive - Video Detector__\n",
        ">These __False Positive - Video Detector__ associations are errors caused by the video detector rather than the association process so they do not effect the association accuracy\n",
        "\n",
        "__False Positive:__\n",
        "\n",
        "If: an association is made that has a cost value greater than the hyper-parameter max_cost __OR__ has a lidar distance value outside of the hyper-parameter __dist_thresh__ (percentage) of the Ground Truth distance \n",
        "\n",
        "Then: the association is labeled a __False Positive:__ (false_pos)\n",
        "\n",
        ">These __False Positive:__ associations are the incorrect associations with a video detection and lidar reading that intersects a Ground Truth object but fails either the max_cost of dist_thresh tests. Note that the Munkres Algorithm always returns the association pairs that have a global minimum cost. Some of these associations may distances that are too far away from the ground truth or may just barely intersect the bounding box and need to be rejected using hyper-parameters.\n",
        "\n",
        "__False Negative:__\n",
        "\n",
        "If: all the associations have been processed and a ground truth object has not been labeled as either a True Positive or a False Positive using the rules above\n",
        "\n",
        "Then: the ground truth object is labeled as a __False Negative__ (false_neg)\n",
        "\n",
        ">These __False Negative__ associations are missing associations that failed to be made either due to the lack of a video detection that intersects with a Ground Truth object or the lack of a lidar detection that intersects with the video detection. The most common of these two faults is the missing video detection. To evaluate the magnitude of the missing video detections, the number of false negatives can be compared using a USE_DETECTION = False hyper-parameter on the association algorithm.\n",
        "\n",
        "\n",
        "__True Negative:__\n",
        "\n",
        "True Negatives are not evaluated in this algorithm because they are not applicable.\n",
        "\n",
        "### Calculating Accuracy, Precision and Recall\n",
        "\n",
        "In addition, the following equations are used to calculate the accuracy, precision and recall of a run.\n",
        "\n",
        "\\begin{equation*}\n",
        "Accuracy = \\frac{True Positives}{(True Positives + False Positives + False Negatives)}\n",
        "\\end{equation*}\n",
        "\n",
        "\\begin{equation*}\n",
        "Precision = \\frac{True Positives}{(True Positives + False Positives)}\n",
        "\\end{equation*}\n",
        "\n",
        "\\begin{equation*}\n",
        "Recall = \\frac{True Positives}{(True Positives + False Negatives)}\n",
        "\\end{equation*}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwVydWe0DZan",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "fa2a5929293b4530b85c14d558f6a336"
          ]
        },
        "outputId": "29d31d67-400f-45d5-87c9-eca74dea99ea"
      },
      "source": [
        "#column_names_2 = ['run_num','use_detector', 'max_cost', 'w0', 'w1', 'w2', 'total_associations', 'accuracy', 'precision', 'recall', 'total_possible_associations', 'true_pos', 'false_pos', 'false_neg']\n",
        "manual_test1 = [0, False, 1, 0.95, 0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "# import pdb; pdb.set_trace()\n",
        "test_results1 = run_association_test(manual_test1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From ../src/detection/car_detector_tf_v2.py:15: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/detection/car_detector_tf_v2.py:16: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/detection/car_detector_tf_v2.py:26: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/detection/yolov3/yolov3.py:585: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From ../src/detection/yolov3/yolov3.py:442: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /mnt/second_drive/PycharmProjects/venv-gpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From ../src/detection/yolov3/yolov3.py:405: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
            "WARNING:tensorflow:From ../src/detection/yolov3/yolov3.py:287: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From ../src/detection/yolov3/yolov3.py:309: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /mnt/second_drive/PycharmProjects/venv-gpu/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From ../src/detection/car_detector_tf_v2.py:28: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/mnt/second_drive/PycharmProjects/venv-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:108: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa2a5929293b4530b85c14d558f6a336",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "run: 0, accy: 0.998, prec: 0.998, recall: 1.000, total_assoc: 452, total_poss_assoc: 452, true_pos: 451, false_pos: 1, false_neg: 0, use_detector:False, max_cost: 1.000, w0: 0.950, w1: 0.050, w2: 0.000\n",
            "\n",
            "Run Complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZViC57E1DZas",
        "colab_type": "code",
        "colab": {},
        "outputId": "db9a7b14-f0bc-496d-c018-ce444a1cafad"
      },
      "source": [
        "test_results1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_num</th>\n",
              "      <th>use_detector</th>\n",
              "      <th>max_cost</th>\n",
              "      <th>w0</th>\n",
              "      <th>w1</th>\n",
              "      <th>w2</th>\n",
              "      <th>total_associations</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>total_possible_associations</th>\n",
              "      <th>true_pos</th>\n",
              "      <th>false_pos</th>\n",
              "      <th>false_neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0</td>\n",
              "      <td>452</td>\n",
              "      <td>0.997788</td>\n",
              "      <td>0.997788</td>\n",
              "      <td>1.0</td>\n",
              "      <td>452</td>\n",
              "      <td>451</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   run_num  use_detector  max_cost    w0    w1  w2  total_associations  \\\n",
              "0        0         False         1  0.95  0.05   0                 452   \n",
              "\n",
              "   accuracy  precision  recall  total_possible_associations  true_pos  \\\n",
              "0  0.997788   0.997788     1.0                          452       451   \n",
              "\n",
              "   false_pos  false_neg  \n",
              "0          1          0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "x7Iaq5E2DZaw",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "0f4539255e194eafb7dcea88bda71d54"
          ]
        },
        "outputId": "0ed9b0ab-fa2f-445c-d8bc-4b787ebe2c24"
      },
      "source": [
        "manual_test2 = [0, True, 1, 0.95, 0.05, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "test_results2 = run_association_test(manual_test2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/mnt/second_drive/PycharmProjects/venv-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:108: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f4539255e194eafb7dcea88bda71d54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "run: 0, accy: 0.834, prec: 0.973, recall: 0.854, total_assoc: 368, total_poss_assoc: 429, true_pos: 358, false_pos: 10, false_neg: 61, use_detector:True, max_cost: 1.000, w0: 0.950, w1: 0.050, w2: 0.000\n",
            "\n",
            "Run Complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0F7sLQxDZa0",
        "colab_type": "code",
        "colab": {},
        "outputId": "8a64ccee-1ed2-497b-b540-94098a58bb83"
      },
      "source": [
        "test_results2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>run_num</th>\n",
              "      <th>use_detector</th>\n",
              "      <th>max_cost</th>\n",
              "      <th>w0</th>\n",
              "      <th>w1</th>\n",
              "      <th>w2</th>\n",
              "      <th>total_associations</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>total_possible_associations</th>\n",
              "      <th>true_pos</th>\n",
              "      <th>false_pos</th>\n",
              "      <th>false_neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0</td>\n",
              "      <td>368</td>\n",
              "      <td>0.834499</td>\n",
              "      <td>0.972826</td>\n",
              "      <td>0.854415</td>\n",
              "      <td>429</td>\n",
              "      <td>358</td>\n",
              "      <td>10</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   run_num  use_detector  max_cost    w0    w1  w2  total_associations  \\\n",
              "0        0          True         1  0.95  0.05   0                 368   \n",
              "\n",
              "   accuracy  precision    recall  total_possible_associations  true_pos  \\\n",
              "0  0.834499   0.972826  0.854415                          429       358   \n",
              "\n",
              "   false_pos  false_neg  \n",
              "0         10         61  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovQuECwVDZa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNYTwwmpDZa8",
        "colab_type": "text"
      },
      "source": [
        "dragon15\n",
        "ddd   +##### "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ij-tNTSDZa9",
        "colab_type": "code",
        "colab": {},
        "outputId": "58a08931-d89e-4aee-a37d-a3f2e0b48f31"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}